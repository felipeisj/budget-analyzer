{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c977e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n completa\n",
      "üìÅ Directorio bases: storage/projects/conservacion_caminos/bases\n",
      "üìÅ Directorio resultados: storage/projects/conservacion_caminos/results\n",
      "üìÅ Directorio temporal: storage/projects/conservacion_caminos/temp\n",
      "üîë API Keys configuradas\n",
      "üöÄ Listo para procesamiento paralelo\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1: CONFIGURACI√ìN E IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuraci√≥n\n",
    "load_dotenv(Path('.env') if Path('.env').exists() else Path('../.env'))\n",
    "\n",
    "# Verificar API keys\n",
    "PDF_REST_API_KEY = os.getenv('PDF_REST_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not PDF_REST_API_KEY:\n",
    "    raise ValueError(\"‚ùå PDF_REST_API_KEY no encontrada en .env\")\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    raise ValueError(\"‚ùå ANTHROPIC_API_KEY no encontrada en .env\")\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "BASE_DIR = Path(\"storage/projects/conservacion_caminos\")\n",
    "BASES_DIR = BASE_DIR / \"bases\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "TEMP_DIR = BASE_DIR / \"temp\"\n",
    "\n",
    "# Crear directorios si no existen\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inicializar cliente Anthropic\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n completa\")\n",
    "print(f\"üìÅ Directorio bases: {BASES_DIR}\")\n",
    "print(f\"üìÅ Directorio resultados: {RESULTS_DIR}\")\n",
    "print(f\"üìÅ Directorio temporal: {TEMP_DIR}\")\n",
    "print(f\"üîë API Keys configuradas\")\n",
    "print(f\"üöÄ Listo para procesamiento paralelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7e3aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n adicional cargada\n",
      "   - tqdm importado para barras de progreso\n",
      "   - CONFIG definido con par√°metros del sistema\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1-B: AGREGAR IMPORTS FALTANTES (ejecutar despu√©s de CELDA 1)\n",
    "# ============================================================================\n",
    "\n",
    "# Imports adicionales necesarios\n",
    "from tqdm.notebook import tqdm  # Para barras de progreso en Jupyter\n",
    "\n",
    "# Configuraci√≥n global que faltaba\n",
    "CONFIG = {\n",
    "    'CHUNK_SIZE': 15,  # P√°ginas por chunk\n",
    "    'MAX_WORKERS': 4,   # Workers paralelos\n",
    "    'OCR_TIMEOUT': 600, # Timeout para OCR (10 minutos)\n",
    "    'MAX_TEXT_FOR_AI': 80000,  # Caracteres m√°ximos para Claude\n",
    "    'MIN_VALID_TEXT': 1000,    # M√≠nimo de caracteres para considerar v√°lido\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n adicional cargada\")\n",
    "print(f\"   - tqdm importado para barras de progreso\")\n",
    "print(f\"   - CONFIG definido con par√°metros del sistema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078b7026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDFSplitter inicializado (30 p√°ginas por chunk)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 2: CLASE PARA DIVISI√ìN DE PDFs\n",
    "# ============================================================================\n",
    "\n",
    "class PDFSplitter:\n",
    "    \"\"\"Divide PDFs grandes en chunks para procesamiento paralelo.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_pages_per_chunk: int = 30):\n",
    "        self.max_pages_per_chunk = max_pages_per_chunk\n",
    "    \n",
    "    def split_pdf(self, pdf_path: Path, output_dir: Path = None) -> List[Tuple[Path, int, int]]:\n",
    "        \"\"\"\n",
    "        Divide PDF en chunks y retorna lista de (chunk_path, start_page, end_page).\n",
    "        \"\"\"\n",
    "        if output_dir is None:\n",
    "            output_dir = TEMP_DIR / f\"{pdf_path.stem}_chunks\"\n",
    "        \n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nüìÑ Dividiendo PDF: {pdf_path.name}\")\n",
    "        print(f\"   üìè Tama√±o: {pdf_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "        \n",
    "        # Obtener total de p√°ginas\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        print(f\"   üìë Total p√°ginas: {total_pages}\")\n",
    "        \n",
    "        chunks_info = []\n",
    "        chunk_number = 1\n",
    "        \n",
    "        for start_page in range(0, total_pages, self.max_pages_per_chunk):\n",
    "            end_page = min(start_page + self.max_pages_per_chunk, total_pages)\n",
    "            \n",
    "            # Crear nombre del chunk\n",
    "            chunk_filename = f\"{pdf_path.stem}_chunk_{chunk_number:02d}_p{start_page+1}-{end_page}.pdf\"\n",
    "            chunk_path = output_dir / chunk_filename\n",
    "            \n",
    "            # Escribir chunk\n",
    "            with open(pdf_path, 'rb') as input_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(input_file)\n",
    "                pdf_writer = PyPDF2.PdfWriter()\n",
    "                \n",
    "                for page_num in range(start_page, end_page):\n",
    "                    pdf_writer.add_page(pdf_reader.pages[page_num])\n",
    "                \n",
    "                with open(chunk_path, 'wb') as output_file:\n",
    "                    pdf_writer.write(output_file)\n",
    "            \n",
    "            chunks_info.append((chunk_path, start_page + 1, end_page))\n",
    "            print(f\"   ‚úÖ Chunk {chunk_number}: p√°ginas {start_page+1}-{end_page}\")\n",
    "            chunk_number += 1\n",
    "        \n",
    "        print(f\"   üì¶ Total chunks creados: {len(chunks_info)}\")\n",
    "        return chunks_info\n",
    "    \n",
    "    def cleanup_chunks(self, chunks_dir: Path):\n",
    "        \"\"\"Limpia los archivos temporales de chunks.\"\"\"\n",
    "        try:\n",
    "            if chunks_dir.exists():\n",
    "                for file in chunks_dir.glob(\"*.pdf\"):\n",
    "                    file.unlink()\n",
    "                chunks_dir.rmdir()\n",
    "                print(f\"   üßπ Limpieza completada: {chunks_dir.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error limpiando chunks: {e}\")\n",
    "\n",
    "# Inicializar splitter\n",
    "splitter = PDFSplitter(max_pages_per_chunk=30)\n",
    "print(\"‚úÖ PDFSplitter inicializado (30 p√°ginas por chunk)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a70462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n optimizada cargada\n",
      "   üìÅ Cache: storage/projects/conservacion_caminos/cache\n",
      "   ‚ö° Workers: 8\n",
      "   üìÑ Chunk size: 10 p√°ginas\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SISTEMA OPTIMIZADO LISTO\n",
      "================================================================================\n",
      "\n",
      "Ejecuta:\n",
      "  >>> results = process_all_pdfs_fast()\n",
      "\n",
      "Esto deber√≠a completarse en menos de 10 minutos\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 3 - PROCESADOR OCR PARA PDFS MOP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "import hashlib\n",
    "import pickle\n",
    "from functools import lru_cache\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN OPTIMIZADA\n",
    "# ============================================================================\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv(Path('.env') if Path('.env').exists() else Path('../.env'))\n",
    "\n",
    "PDF_REST_API_KEY = os.getenv('PDF_REST_API_KEY')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if not PDF_REST_API_KEY:\n",
    "    raise ValueError(\"‚ùå PDF_REST_API_KEY no encontrada en .env\")\n",
    "\n",
    "# Configuraci√≥n de rutas\n",
    "BASE_DIR = Path(\"storage/projects/conservacion_caminos\")\n",
    "BASES_DIR = BASE_DIR / \"bases\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "TEMP_DIR = BASE_DIR / \"temp\"\n",
    "CACHE_DIR = BASE_DIR / \"cache\"  # Nuevo directorio de cach√©\n",
    "\n",
    "# Crear directorios\n",
    "for dir_path in [RESULTS_DIR, TEMP_DIR, CACHE_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cliente Anthropic (opcional - solo si necesitas an√°lisis IA)\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY) if ANTHROPIC_API_KEY else None\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACI√ìN OPTIMIZADA DEL SISTEMA\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    'CHUNK_SIZE': 10,        # Reducido de 30 a 10 p√°ginas\n",
    "    'MAX_WORKERS': 8,        # Aumentado de 3-4 a 8 workers\n",
    "    'OCR_TIMEOUT': 120,      # Reducido de 300-600 a 120 segundos\n",
    "    'RETRY_COUNT': 1,        # Reducido de 2 a 1 reintento\n",
    "    'USE_CACHE': True,       # Activar cach√©\n",
    "    'PARALLEL_MODE': 'thread',  # 'thread' o 'process'\n",
    "    'BATCH_SIZE': 5,         # Procesar en batches\n",
    "    'MIN_VALID_TEXT': 500,   # M√≠nimo de caracteres\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n optimizada cargada\")\n",
    "print(f\"   üìÅ Cache: {CACHE_DIR}\")\n",
    "print(f\"   ‚ö° Workers: {CONFIG['MAX_WORKERS']}\")\n",
    "print(f\"   üìÑ Chunk size: {CONFIG['CHUNK_SIZE']} p√°ginas\")\n",
    "\n",
    "# ============================================================================\n",
    "# SISTEMA DE CACH√â INTELIGENTE\n",
    "# ============================================================================\n",
    "\n",
    "class SmartCache:\n",
    "    \"\"\"Sistema de cach√© para evitar reprocesar chunks.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path):\n",
    "        self.cache_dir = cache_dir\n",
    "        self.index_file = cache_dir / \"cache_index.json\"\n",
    "        self.index = self._load_index()\n",
    "    \n",
    "    def _load_index(self):\n",
    "        if self.index_file.exists():\n",
    "            with open(self.index_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def _save_index(self):\n",
    "        with open(self.index_file, 'w') as f:\n",
    "            json.dump(self.index, f)\n",
    "    \n",
    "    def get_hash(self, file_path: Path, start_page: int, end_page: int) -> str:\n",
    "        \"\"\"Genera hash √∫nico para un chunk.\"\"\"\n",
    "        key = f\"{file_path.name}_{start_page}_{end_page}_{file_path.stat().st_mtime}\"\n",
    "        return hashlib.md5(key.encode()).hexdigest()\n",
    "    \n",
    "    def get(self, hash_key: str) -> Optional[Dict]:\n",
    "        \"\"\"Recupera resultado cacheado si existe.\"\"\"\n",
    "        if hash_key in self.index:\n",
    "            cache_file = self.cache_dir / f\"{hash_key}.pkl\"\n",
    "            if cache_file.exists():\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "        return None\n",
    "    \n",
    "    def set(self, hash_key: str, data: Dict):\n",
    "        \"\"\"Guarda resultado en cach√©.\"\"\"\n",
    "        cache_file = self.cache_dir / f\"{hash_key}.pkl\"\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        self.index[hash_key] = time.time()\n",
    "        self._save_index()\n",
    "\n",
    "cache = SmartCache(CACHE_DIR)\n",
    "\n",
    "# ============================================================================\n",
    "# SPLITTER OPTIMIZADO\n",
    "# ============================================================================\n",
    "\n",
    "class OptimizedPDFSplitter:\n",
    "    \"\"\"Divisi√≥n optimizada de PDFs.\"\"\"\n",
    "    \n",
    "    def __init__(self, pages_per_chunk: int = 10):\n",
    "        self.pages_per_chunk = pages_per_chunk\n",
    "    \n",
    "    def split_pdf_fast(self, pdf_path: Path) -> List[Tuple[Path, int, int]]:\n",
    "        \"\"\"Divisi√≥n r√°pida de PDF sin escribir chunks intermedios si no es necesario.\"\"\"\n",
    "        chunks_info = []\n",
    "        \n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        print(f\"üìÑ PDF: {pdf_path.name} ({total_pages} p√°ginas)\")\n",
    "        \n",
    "        # Crear directorio para chunks\n",
    "        chunks_dir = TEMP_DIR / f\"{pdf_path.stem}_chunks\"\n",
    "        chunks_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Dividir en chunks m√°s peque√±os\n",
    "        for i, start in enumerate(range(0, total_pages, self.pages_per_chunk), 1):\n",
    "            end = min(start + self.pages_per_chunk, total_pages)\n",
    "            chunk_path = chunks_dir / f\"{pdf_path.stem}_chunk_{i:03d}.pdf\"\n",
    "            \n",
    "            # Solo crear el chunk si no est√° cacheado\n",
    "            cache_key = cache.get_hash(pdf_path, start, end)\n",
    "            if CONFIG['USE_CACHE'] and cache.get(cache_key):\n",
    "                print(f\"   üì¶ Chunk {i}: p√°ginas {start+1}-{end} [CACHEADO]\")\n",
    "            else:\n",
    "                # Crear chunk\n",
    "                with open(pdf_path, 'rb') as input_file:\n",
    "                    reader = PyPDF2.PdfReader(input_file)\n",
    "                    writer = PyPDF2.PdfWriter()\n",
    "                    \n",
    "                    for page_num in range(start, end):\n",
    "                        writer.add_page(reader.pages[page_num])\n",
    "                    \n",
    "                    with open(chunk_path, 'wb') as output_file:\n",
    "                        writer.write(output_file)\n",
    "                \n",
    "                print(f\"   üì¶ Chunk {i}: p√°ginas {start+1}-{end}\")\n",
    "            \n",
    "            chunks_info.append((chunk_path, start + 1, end, cache_key))\n",
    "        \n",
    "        return chunks_info\n",
    "\n",
    "# ============================================================================\n",
    "# OCR OPTIMIZADO CON BATCHING\n",
    "# ============================================================================\n",
    "\n",
    "def apply_ocr_optimized(chunk_info: Tuple) -> Dict[str, Any]:\n",
    "    \"\"\"OCR optimizado con cach√© y timeouts reducidos.\"\"\"\n",
    "    chunk_path, start_page, end_page, cache_key = chunk_info\n",
    "    \n",
    "    # Verificar cach√©\n",
    "    if CONFIG['USE_CACHE']:\n",
    "        cached = cache.get(cache_key)\n",
    "        if cached:\n",
    "            return cached\n",
    "    \n",
    "    result = {\n",
    "        \"chunk_name\": chunk_path.name,\n",
    "        \"pages\": (start_page, end_page),\n",
    "        \"success\": False,\n",
    "        \"text\": \"\",\n",
    "        \"error\": None,\n",
    "        \"processing_time\": 0,\n",
    "        \"characters\": 0\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Si el archivo no existe (porque estaba cacheado), retornar cach√© vac√≠o\n",
    "    if not chunk_path.exists():\n",
    "        result[\"error\"] = \"Chunk file not found (likely cached)\"\n",
    "        return result\n",
    "    \n",
    "    try:\n",
    "        # OCR con timeout reducido\n",
    "        ocr_url = \"https://api.pdfrest.com/pdf-with-ocr-text\"\n",
    "        \n",
    "        with open(chunk_path, 'rb') as file:\n",
    "            files = [('file', (chunk_path.name, file, 'application/pdf'))]\n",
    "            headers = {'Api-Key': PDF_REST_API_KEY}\n",
    "            payload = {\n",
    "                'output': f'ocr_{chunk_path.stem}',\n",
    "                'languages': 'Spanish'\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                ocr_url,\n",
    "                headers=headers,\n",
    "                data=payload,\n",
    "                files=files,\n",
    "                timeout=CONFIG['OCR_TIMEOUT']\n",
    "            )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            output_url = data.get('outputUrl')\n",
    "            \n",
    "            if output_url:\n",
    "                # Descargar y extraer texto\n",
    "                pdf_response = requests.get(output_url, timeout=30)\n",
    "                \n",
    "                if pdf_response.status_code == 200:\n",
    "                    # Guardar temporalmente\n",
    "                    temp_pdf = TEMP_DIR / f\"temp_{chunk_path.stem}.pdf\"\n",
    "                    with open(temp_pdf, 'wb') as f:\n",
    "                        f.write(pdf_response.content)\n",
    "                    \n",
    "                    # Extraer texto\n",
    "                    extract_url = \"https://api.pdfrest.com/extracted-text\"\n",
    "                    with open(temp_pdf, 'rb') as file:\n",
    "                        files = [('file', (temp_pdf.name, file, 'application/pdf'))]\n",
    "                        response = requests.post(\n",
    "                            extract_url, \n",
    "                            headers=headers, \n",
    "                            files=files, \n",
    "                            timeout=30\n",
    "                        )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        text = response.json().get('fullText', '')\n",
    "                        text = re.sub(r'\\[pdfRest.*?\\]', '', text)\n",
    "                        \n",
    "                        result[\"success\"] = True\n",
    "                        result[\"text\"] = text\n",
    "                        result[\"characters\"] = len(text)\n",
    "                    \n",
    "                    # Limpiar temporal\n",
    "                    if temp_pdf.exists():\n",
    "                        temp_pdf.unlink()\n",
    "    \n",
    "    except requests.Timeout:\n",
    "        result[\"error\"] = f\"Timeout ({CONFIG['OCR_TIMEOUT']}s)\"\n",
    "    except Exception as e:\n",
    "        result[\"error\"] = str(e)[:100]\n",
    "    \n",
    "    result[\"processing_time\"] = time.time() - start_time\n",
    "    \n",
    "    # Guardar en cach√© si fue exitoso\n",
    "    if CONFIG['USE_CACHE'] and result[\"success\"]:\n",
    "        cache.set(cache_key, result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESAMIENTO PARALELO OPTIMIZADO\n",
    "# ============================================================================\n",
    "\n",
    "def process_chunks_batch_parallel(chunks_info: List[Tuple], max_workers: int = None) -> Dict:\n",
    "    \"\"\"Procesamiento paralelo optimizado con batching.\"\"\"\n",
    "    if max_workers is None:\n",
    "        max_workers = CONFIG['MAX_WORKERS']\n",
    "    \n",
    "    print(f\"\\n‚ö° Procesando {len(chunks_info)} chunks con {max_workers} workers\")\n",
    "    \n",
    "    results = []\n",
    "    texts_by_page = {}\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    cached = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Procesar en batches para mejor control\n",
    "        batch_size = CONFIG['BATCH_SIZE']\n",
    "        \n",
    "        with tqdm(total=len(chunks_info), desc=\"Procesando chunks\") as pbar:\n",
    "            for i in range(0, len(chunks_info), batch_size):\n",
    "                batch = chunks_info[i:i+batch_size]\n",
    "                \n",
    "                # Enviar batch\n",
    "                futures = {\n",
    "                    executor.submit(apply_ocr_optimized, chunk): chunk \n",
    "                    for chunk in batch\n",
    "                }\n",
    "                \n",
    "                # Procesar resultados del batch\n",
    "                for future in as_completed(futures):\n",
    "                    chunk_info = futures[future]\n",
    "                    try:\n",
    "                        result = future.result(timeout=CONFIG['OCR_TIMEOUT'] + 10)\n",
    "                        results.append(result)\n",
    "                        \n",
    "                        if result[\"success\"]:\n",
    "                            start_page = result[\"pages\"][0]\n",
    "                            texts_by_page[start_page] = result[\"text\"]\n",
    "                            successful += 1\n",
    "                            \n",
    "                            # Verificar si vino de cach√©\n",
    "                            if result[\"processing_time\"] < 0.1:\n",
    "                                cached += 1\n",
    "                        else:\n",
    "                            failed += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        failed += 1\n",
    "                        print(f\"‚ùå Error: {str(e)[:50]}\")\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    \n",
    "    # Consolidar texto en orden\n",
    "    consolidated_text = \"\"\n",
    "    for page_num in sorted(texts_by_page.keys()):\n",
    "        consolidated_text += f\"\\n\\n--- P√°ginas {page_num} ---\\n\"\n",
    "        consolidated_text += texts_by_page[page_num]\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nüìä Resultados:\")\n",
    "    print(f\"   ‚úÖ Exitosos: {successful}/{len(chunks_info)}\")\n",
    "    print(f\"   üíæ Desde cach√©: {cached}\")\n",
    "    print(f\"   ‚ùå Fallidos: {failed}\")\n",
    "    print(f\"   ‚è±Ô∏è Tiempo: {elapsed:.1f}s ({elapsed/len(chunks_info):.1f}s/chunk)\")\n",
    "    \n",
    "    return {\n",
    "        \"success\": successful > 0,\n",
    "        \"text\": consolidated_text,\n",
    "        \"chunks_processed\": len(chunks_info),\n",
    "        \"chunks_successful\": successful,\n",
    "        \"chunks_failed\": failed,\n",
    "        \"chunks_cached\": cached,\n",
    "        \"total_characters\": len(consolidated_text),\n",
    "        \"processing_time\": elapsed\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PRINCIPAL OPTIMIZADA\n",
    "# ============================================================================\n",
    "\n",
    "def process_pdf_fast(pdf_path: Path, skip_ai: bool = True) -> Dict:\n",
    "    \"\"\"Procesa un PDF de forma optimizada.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚ö° PROCESAMIENTO R√ÅPIDO: {pdf_path.name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    total_start = time.time()\n",
    "    \n",
    "    # Verificar texto existente\n",
    "    text_file = RESULTS_DIR / f\"{pdf_path.stem}_texto.txt\"\n",
    "    if text_file.exists() and not CONFIG.get('FORCE_REPROCESS', False):\n",
    "        print(f\"‚úÖ Texto ya existe: {text_file.name}\")\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"text\": text,\n",
    "            \"cached\": True,\n",
    "            \"processing_time\": 0\n",
    "        }\n",
    "    \n",
    "    # Dividir PDF\n",
    "    splitter = OptimizedPDFSplitter(pages_per_chunk=CONFIG['CHUNK_SIZE'])\n",
    "    chunks_info = splitter.split_pdf_fast(pdf_path)\n",
    "    \n",
    "    # Procesar chunks en paralelo\n",
    "    result = process_chunks_batch_parallel(chunks_info)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        # Guardar texto\n",
    "        text = result[\"text\"]\n",
    "        with open(text_file, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "            f.write(text)\n",
    "        print(f\"üíæ Guardado: {text_file.name}\")\n",
    "        \n",
    "        # Extraer patrones b√°sicos (r√°pido)\n",
    "        patterns = extract_patterns_quick(text)\n",
    "        \n",
    "        # Guardar resumen b√°sico\n",
    "        summary = {\n",
    "            \"filename\": pdf_path.name,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"total_characters\": len(text),\n",
    "            \"processing_time\": time.time() - total_start,\n",
    "            \"chunks_cached\": result.get(\"chunks_cached\", 0),\n",
    "            \"patterns\": {\n",
    "                \"mop_codes\": len(patterns.get('mop_codes', [])),\n",
    "                \"ete_codes\": len(patterns.get('ete_codes', [])),\n",
    "                \"montos\": len(patterns.get('montos', []))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_file = RESULTS_DIR / f\"{pdf_path.stem}_resumen_rapido.json\"\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Completado en {time.time() - total_start:.1f}s\")\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"text\": text,\n",
    "            \"summary\": summary,\n",
    "            \"processing_time\": time.time() - total_start\n",
    "        }\n",
    "    \n",
    "    return {\"success\": False, \"error\": \"Fall√≥ el procesamiento\"}\n",
    "\n",
    "def extract_patterns_quick(text: str) -> Dict:\n",
    "    \"\"\"Extracci√≥n r√°pida de patrones sin regex complejos.\"\"\"\n",
    "    return {\n",
    "        'mop_codes': re.findall(r'7\\.\\d{3}\\.\\d+', text)[:100],  # Limitar resultados\n",
    "        'ete_codes': re.findall(r'ETE[\\.\\-\\s]?\\d+', text, re.IGNORECASE)[:50],\n",
    "        'montos': re.findall(r'\\$\\s*[\\d\\.,]+', text)[:100]\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESAMIENTO EN BATCH OPTIMIZADO\n",
    "# ============================================================================\n",
    "\n",
    "def process_all_pdfs_fast():\n",
    "    \"\"\"Procesa todos los PDFs de forma optimizada.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö° PROCESAMIENTO BATCH OPTIMIZADO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Buscar PDFs\n",
    "    pdf_files = list(BASES_DIR.glob(\"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(\"‚ùå No se encontraron PDFs\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üìö Archivos encontrados: {len(pdf_files)}\")\n",
    "    for pdf in pdf_files:\n",
    "        size_mb = pdf.stat().st_size / 1024 / 1024\n",
    "        print(f\"   - {pdf.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Procesar todos\n",
    "    results = []\n",
    "    for idx, pdf_path in enumerate(pdf_files, 1):\n",
    "        print(f\"\\n[{idx}/{len(pdf_files)}] Procesando: {pdf_path.name}\")\n",
    "        result = process_pdf_fast(pdf_path, skip_ai=True)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result[\"success\"]:\n",
    "            print(f\"   ‚úÖ {result['summary']['total_characters']:,} caracteres\")\n",
    "            print(f\"   ‚è±Ô∏è {result['processing_time']:.1f}s\")\n",
    "    \n",
    "    # Resumen final\n",
    "    total_time = time.time() - start_time\n",
    "    successful = sum(1 for r in results if r[\"success\"])\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìä RESUMEN FINAL\")\n",
    "    print(f\"=\"*80)\n",
    "    print(f\"‚úÖ Exitosos: {successful}/{len(pdf_files)}\")\n",
    "    print(f\"‚è±Ô∏è Tiempo total: {total_time:.1f}s\")\n",
    "    print(f\"‚ö° Promedio: {total_time/len(pdf_files):.1f}s por archivo\")\n",
    "    \n",
    "    # Generar tabla resumen\n",
    "    summary_data = []\n",
    "    for pdf, result in zip(pdf_files, results):\n",
    "        if result[\"success\"]:\n",
    "            summary_data.append({\n",
    "                'Archivo': pdf.name,\n",
    "                'Tama√±o MB': round(pdf.stat().st_size / 1024 / 1024, 1),\n",
    "                'Caracteres': result['summary']['total_characters'],\n",
    "                'C√≥digos MOP': result['summary']['patterns']['mop_codes'],\n",
    "                'Tiempo (s)': round(result['processing_time'], 1),\n",
    "                'Chunks Cache': result['summary'].get('chunks_cached', 0)\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        display(df)\n",
    "        \n",
    "        # Guardar Excel\n",
    "        excel_file = RESULTS_DIR / f\"resumen_optimizado_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f\"\\nüíæ Resumen guardado: {excel_file}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN DE LIMPIEZA\n",
    "# ============================================================================\n",
    "\n",
    "def cleanup_temp_files():\n",
    "    \"\"\"Limpia archivos temporales.\"\"\"\n",
    "    print(\"üßπ Limpiando archivos temporales...\")\n",
    "    \n",
    "    # Limpiar chunks\n",
    "    for chunk_dir in TEMP_DIR.glob(\"*_chunks\"):\n",
    "        for file in chunk_dir.glob(\"*.pdf\"):\n",
    "            file.unlink()\n",
    "        chunk_dir.rmdir()\n",
    "    \n",
    "    # Limpiar PDFs temporales\n",
    "    for temp_pdf in TEMP_DIR.glob(\"temp_*.pdf\"):\n",
    "        temp_pdf.unlink()\n",
    "    \n",
    "    print(\"‚úÖ Limpieza completada\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SISTEMA OPTIMIZADO LISTO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nEjecuta:\")\n",
    "print(\"  >>> results = process_all_pdfs_fast()\")\n",
    "print(\"\\nEsto deber√≠a completarse en menos de 10 minutos\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14a11c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚ö° PROCESAMIENTO BATCH OPTIMIZADO\n",
      "================================================================================\n",
      "üìö Archivos encontrados: 3\n",
      "   - bases2.pdf (7.6 MB)\n",
      "   - bases3.pdf (17.3 MB)\n",
      "   - bases1.pdf (12.2 MB)\n",
      "\n",
      "[1/3] Procesando: bases2.pdf\n",
      "\n",
      "======================================================================\n",
      "‚ö° PROCESAMIENTO R√ÅPIDO: bases2.pdf\n",
      "======================================================================\n",
      "üìÑ PDF: bases2.pdf (150 p√°ginas)\n",
      "   üì¶ Chunk 1: p√°ginas 1-10 [CACHEADO]\n",
      "   üì¶ Chunk 2: p√°ginas 11-20 [CACHEADO]\n",
      "   üì¶ Chunk 3: p√°ginas 21-30 [CACHEADO]\n",
      "   üì¶ Chunk 4: p√°ginas 31-40 [CACHEADO]\n",
      "   üì¶ Chunk 5: p√°ginas 41-50 [CACHEADO]\n",
      "   üì¶ Chunk 6: p√°ginas 51-60 [CACHEADO]\n",
      "   üì¶ Chunk 7: p√°ginas 61-70 [CACHEADO]\n",
      "   üì¶ Chunk 8: p√°ginas 71-80 [CACHEADO]\n",
      "   üì¶ Chunk 9: p√°ginas 81-90 [CACHEADO]\n",
      "   üì¶ Chunk 10: p√°ginas 91-100 [CACHEADO]\n",
      "   üì¶ Chunk 11: p√°ginas 101-110 [CACHEADO]\n",
      "   üì¶ Chunk 12: p√°ginas 111-120 [CACHEADO]\n",
      "   üì¶ Chunk 13: p√°ginas 121-130 [CACHEADO]\n",
      "   üì¶ Chunk 14: p√°ginas 131-140 [CACHEADO]\n",
      "   üì¶ Chunk 15: p√°ginas 141-150 [CACHEADO]\n",
      "\n",
      "‚ö° Procesando 15 chunks con 8 workers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d0c195491a442fb28a17a8a24c796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando chunks:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Resultados:\n",
      "   ‚úÖ Exitosos: 15/15\n",
      "   üíæ Desde cach√©: 0\n",
      "   ‚ùå Fallidos: 0\n",
      "   ‚è±Ô∏è Tiempo: 0.0s (0.0s/chunk)\n",
      "üíæ Guardado: bases2_texto.txt\n",
      "\n",
      "‚úÖ Completado en 0.1s\n",
      "   ‚úÖ 338,247 caracteres\n",
      "   ‚è±Ô∏è 0.1s\n",
      "\n",
      "[2/3] Procesando: bases3.pdf\n",
      "\n",
      "======================================================================\n",
      "‚ö° PROCESAMIENTO R√ÅPIDO: bases3.pdf\n",
      "======================================================================\n",
      "üìÑ PDF: bases3.pdf (135 p√°ginas)\n",
      "   üì¶ Chunk 1: p√°ginas 1-10 [CACHEADO]\n",
      "   üì¶ Chunk 2: p√°ginas 11-20 [CACHEADO]\n",
      "   üì¶ Chunk 3: p√°ginas 21-30 [CACHEADO]\n",
      "   üì¶ Chunk 4: p√°ginas 31-40 [CACHEADO]\n",
      "   üì¶ Chunk 5: p√°ginas 41-50 [CACHEADO]\n",
      "   üì¶ Chunk 6: p√°ginas 51-60 [CACHEADO]\n",
      "   üì¶ Chunk 7: p√°ginas 61-70 [CACHEADO]\n",
      "   üì¶ Chunk 8: p√°ginas 71-80 [CACHEADO]\n",
      "   üì¶ Chunk 9: p√°ginas 81-90 [CACHEADO]\n",
      "   üì¶ Chunk 10: p√°ginas 91-100 [CACHEADO]\n",
      "   üì¶ Chunk 11: p√°ginas 101-110 [CACHEADO]\n",
      "   üì¶ Chunk 12: p√°ginas 111-120 [CACHEADO]\n",
      "   üì¶ Chunk 13: p√°ginas 121-130 [CACHEADO]\n",
      "   üì¶ Chunk 14: p√°ginas 131-135 [CACHEADO]\n",
      "\n",
      "‚ö° Procesando 14 chunks con 8 workers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7594b943fb4c4b13a34c0dfccd3c7151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando chunks:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Resultados:\n",
      "   ‚úÖ Exitosos: 14/14\n",
      "   üíæ Desde cach√©: 0\n",
      "   ‚ùå Fallidos: 0\n",
      "   ‚è±Ô∏è Tiempo: 0.0s (0.0s/chunk)\n",
      "üíæ Guardado: bases3_texto.txt\n",
      "\n",
      "‚úÖ Completado en 0.0s\n",
      "   ‚úÖ 308,486 caracteres\n",
      "   ‚è±Ô∏è 0.0s\n",
      "\n",
      "[3/3] Procesando: bases1.pdf\n",
      "\n",
      "======================================================================\n",
      "‚ö° PROCESAMIENTO R√ÅPIDO: bases1.pdf\n",
      "======================================================================\n",
      "üìÑ PDF: bases1.pdf (100 p√°ginas)\n",
      "   üì¶ Chunk 1: p√°ginas 1-10 [CACHEADO]\n",
      "   üì¶ Chunk 2: p√°ginas 11-20 [CACHEADO]\n",
      "   üì¶ Chunk 3: p√°ginas 21-30 [CACHEADO]\n",
      "   üì¶ Chunk 4: p√°ginas 31-40 [CACHEADO]\n",
      "   üì¶ Chunk 5: p√°ginas 41-50 [CACHEADO]\n",
      "   üì¶ Chunk 6: p√°ginas 51-60 [CACHEADO]\n",
      "   üì¶ Chunk 7: p√°ginas 61-70 [CACHEADO]\n",
      "   üì¶ Chunk 8: p√°ginas 71-80 [CACHEADO]\n",
      "   üì¶ Chunk 9: p√°ginas 81-90 [CACHEADO]\n",
      "   üì¶ Chunk 10: p√°ginas 91-100 [CACHEADO]\n",
      "\n",
      "‚ö° Procesando 10 chunks con 8 workers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691d368022724c6da6a1d541d09c7228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando chunks:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Resultados:\n",
      "   ‚úÖ Exitosos: 10/10\n",
      "   üíæ Desde cach√©: 0\n",
      "   ‚ùå Fallidos: 0\n",
      "   ‚è±Ô∏è Tiempo: 0.0s (0.0s/chunk)\n",
      "üíæ Guardado: bases1_texto.txt\n",
      "\n",
      "‚úÖ Completado en 0.1s\n",
      "   ‚úÖ 221,552 caracteres\n",
      "   ‚è±Ô∏è 0.1s\n",
      "\n",
      "================================================================================\n",
      "üìä RESUMEN FINAL\n",
      "================================================================================\n",
      "‚úÖ Exitosos: 3/3\n",
      "‚è±Ô∏è Tiempo total: 0.2s\n",
      "‚ö° Promedio: 0.1s por archivo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "      <th>Tama√±o MB</th>\n",
       "      <th>Caracteres</th>\n",
       "      <th>C√≥digos MOP</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "      <th>Chunks Cache</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bases2.pdf</td>\n",
       "      <td>7.6</td>\n",
       "      <td>338247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bases3.pdf</td>\n",
       "      <td>17.3</td>\n",
       "      <td>308486</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bases1.pdf</td>\n",
       "      <td>12.2</td>\n",
       "      <td>221552</td>\n",
       "      <td>27</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Archivo  Tama√±o MB  Caracteres  C√≥digos MOP  Tiempo (s)  Chunks Cache\n",
       "0  bases2.pdf        7.6      338247            0         0.1             0\n",
       "1  bases3.pdf       17.3      308486          100         0.0             0\n",
       "2  bases1.pdf       12.2      221552           27         0.1             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Resumen guardado: storage/projects/conservacion_caminos/results/resumen_optimizado_20250906_0108.xlsx\n"
     ]
    }
   ],
   "source": [
    "results = process_all_pdfs_fast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395155e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36757031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ ANALIZADOR MOP COMPLETO CARGADO (VERSI√ìN CORREGIDA)\n",
      "================================================================================\n",
      "\n",
      "Funciones disponibles:\n",
      "  ‚Ä¢ analyze_single_document('bases1_texto.txt') - Analiza un documento espec√≠fico\n",
      "  ‚Ä¢ analyze_all_documents_auto() - Analiza todos los documentos extra√≠dos\n",
      "  ‚Ä¢ test_budget_correction() - Prueba correcci√≥n de presupuesto\n",
      "\n",
      "üí° Flujo recomendado:\n",
      "  1. test_budget_correction() - Verificar correcciones\n",
      "  2. analyze_single_document('nombre_archivo_texto.txt') - Probar con uno\n",
      "  3. analyze_all_documents_auto() - Procesar todos\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4: ANALIZADOR MOP COMPLETO E INTEGRADO (VERSI√ìN CORREGIDA)\n",
    "# ============================================================================\n",
    "\n",
    "class MOPBudgetAnalyzer:\n",
    "    \"\"\"\n",
    "    Analizador completo para documentos MOP con correcci√≥n de presupuestos,\n",
    "    control de tokens y rate limiting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client: anthropic.Anthropic):\n",
    "        self.client = client\n",
    "        self.model = \"claude-3-5-haiku-20241022\"  # M√°s econ√≥mico\n",
    "        self.expected_total = 718998624  # Total esperado del presupuesto\n",
    "        self.last_request_time = 0\n",
    "        self.max_tokens_input = 15000\n",
    "        self.delay_between_requests = 30\n",
    "        \n",
    "    def _check_rate_limit(self):\n",
    "        \"\"\"Verifica y espera si es necesario para respetar rate limits.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        \n",
    "        if time_since_last < self.delay_between_requests:\n",
    "            sleep_time = self.delay_between_requests - time_since_last\n",
    "            print(f\"‚è≥ Esperando {sleep_time:.1f}s para respetar rate limits...\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "    def quick_document_analysis(self, text: str, filename: str) -> Dict:\n",
    "        \"\"\"\n",
    "        An√°lisis r√°pido sin usar Claude para identificar tipo de documento.\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Detectar tipo de documento\n",
    "        doc_type = \"documento_mop\"\n",
    "        if \"presupuesto oficial\" in text_lower or (\"total general\" in text_lower and \"iva\" in text_lower):\n",
    "            doc_type = \"presupuesto\"\n",
    "        elif \"bases administrativas\" in text_lower:\n",
    "            doc_type = \"bases_administrativas\"  \n",
    "        elif \"especificaciones\" in text_lower and (\"t√©cnicas\" in text_lower or \"ambientales\" in text_lower):\n",
    "            doc_type = \"especificaciones\"\n",
    "        \n",
    "        # Extraer informaci√≥n b√°sica del proyecto\n",
    "        proyecto_info = self._extract_project_info_regex(text)\n",
    "        \n",
    "        # Buscar c√≥digos MOP\n",
    "        codigos_mop = re.findall(r'7\\.\\d{3}\\.\\d{1,3}[a-z]?', text)\n",
    "        \n",
    "        # Buscar totales monetarios (formato chileno con puntos)\n",
    "        totales = re.findall(r'\\$\\s*(\\d{1,3}(?:\\.\\d{3})+)', text)\n",
    "        totales_numericos = [int(t.replace('.', '')) for t in totales if len(t.replace('.', '')) >= 6]\n",
    "        \n",
    "        # Buscar informaci√≥n espec√≠fica del presupuesto\n",
    "        budget_info = self._extract_budget_info_regex(text)\n",
    "        \n",
    "        return {\n",
    "            \"tipo_documento\": doc_type,\n",
    "            \"proyecto_detectado\": proyecto_info,\n",
    "            \"codigos_mop_encontrados\": len(codigos_mop),\n",
    "            \"codigos_mop_lista\": codigos_mop[:10],  # Primeros 10\n",
    "            \"totales_monetarios\": totales_numericos[:5],\n",
    "            \"budget_data\": budget_info,\n",
    "            \"tiene_datos_presupuestarios\": len(codigos_mop) > 0 or (doc_type == \"presupuesto\"),\n",
    "            \"confianza_deteccion\": self._calculate_confidence(doc_type, len(codigos_mop), proyecto_info)\n",
    "        }\n",
    "    \n",
    "    def _extract_project_info_regex(self, text: str) -> Dict:\n",
    "        \"\"\"Extrae informaci√≥n del proyecto usando regex (VERSI√ìN CORREGIDA).\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        info = {\n",
    "            \"nombre\": \"\",\n",
    "            \"region\": \"\",\n",
    "            \"comunas\": [],\n",
    "            \"tipo_obra\": \"\",\n",
    "            \"etapa\": \"\",\n",
    "            \"provincia\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Buscar nombre del proyecto - m√©todo simplificado y seguro\n",
    "        if \"conservaci√≥n\" in text_lower and \"caminos\" in text_lower:\n",
    "            if \"comunidades ind√≠genas\" in text_lower:\n",
    "                if \"etapa xii\" in text_lower or \"etapa 12\" in text_lower:\n",
    "                    info[\"nombre\"] = \"Conservaci√≥n de caminos de acceso a comunidades ind√≠genas Etapa XII\"\n",
    "                else:\n",
    "                    info[\"nombre\"] = \"Conservaci√≥n de caminos de acceso a comunidades ind√≠genas\"\n",
    "            else:\n",
    "                info[\"nombre\"] = \"Conservaci√≥n de caminos\"\n",
    "        \n",
    "        if not info[\"nombre\"]:\n",
    "            # Buscar patr√≥n m√°s general de forma segura\n",
    "            proyecto_match = re.search(r'proyecto[:\\s]*([^,\\n]{10,100})', text_lower)\n",
    "            if proyecto_match:\n",
    "                info[\"nombre\"] = proyecto_match.group(1).strip().title()\n",
    "            else:\n",
    "                info[\"nombre\"] = \"Proyecto MOP\"\n",
    "        \n",
    "        # Buscar etapa\n",
    "        if \"etapa xii\" in text_lower or \"etapa 12\" in text_lower or \"etapa doce\" in text_lower:\n",
    "            info[\"etapa\"] = \"Etapa XII\"\n",
    "        \n",
    "        # Buscar regi√≥n - CORREGIDO y simplificado\n",
    "        if \"los r√≠os\" in text_lower or \"regi√≥n de los r√≠os\" in text_lower:\n",
    "            info[\"region\"] = \"Los R√≠os\"\n",
    "        else:\n",
    "            region_match = re.search(r'regi√≥n[:\\s]+de\\s+([^,\\n.]+)', text_lower)\n",
    "            if region_match:\n",
    "                info[\"region\"] = region_match.group(1).strip().title()\n",
    "            else:\n",
    "                # B√∫squeda m√°s general\n",
    "                region_match = re.search(r'regi√≥n[:\\s]+([^,\\n.]{3,30})', text_lower)\n",
    "                if region_match:\n",
    "                    info[\"region\"] = region_match.group(1).strip().title()\n",
    "        \n",
    "        # Buscar provincia - CORREGIDO\n",
    "        if \"del ranco\" in text_lower or \"provincia del ranco\" in text_lower:\n",
    "            info[\"provincia\"] = \"Del Ranco\"\n",
    "        else:\n",
    "            # Patr√≥n m√°s espec√≠fico para evitar errores\n",
    "            provincia_match = re.search(r'provincia\\s+del?\\s+([^,\\n.]{3,30})', text_lower)\n",
    "            if provincia_match:\n",
    "                info[\"provincia\"] = provincia_match.group(1).strip().title()\n",
    "        \n",
    "        # Buscar comunas - simplificado y seguro\n",
    "        comunas_encontradas = []\n",
    "        if \"lago ranco\" in text_lower:\n",
    "            comunas_encontradas.append(\"Lago Ranco\")\n",
    "        if \"futrono\" in text_lower:\n",
    "            comunas_encontradas.append(\"Futrono\")\n",
    "        if \"valdivia\" in text_lower:\n",
    "            comunas_encontradas.append(\"Valdivia\")\n",
    "        \n",
    "        # Si no encuentra las espec√≠ficas, buscar patr√≥n general\n",
    "        if not comunas_encontradas:\n",
    "            comuna_match = re.search(r'comuna[s]?\\s+de\\s+([^,\\n.]+)', text_lower)\n",
    "            if comuna_match:\n",
    "                comunas_text = comuna_match.group(1).strip()\n",
    "                # Dividir si hay \"y\" o \",\"\n",
    "                if \" y \" in comunas_text:\n",
    "                    comunas_encontradas = [c.strip().title() for c in comunas_text.split(\" y \")]\n",
    "                elif \",\" in comunas_text:\n",
    "                    comunas_encontradas = [c.strip().title() for c in comunas_text.split(\",\")]\n",
    "                else:\n",
    "                    comunas_encontradas = [comunas_text.title()]\n",
    "        \n",
    "        info[\"comunas\"] = comunas_encontradas if comunas_encontradas else [\"Por determinar\"]\n",
    "        \n",
    "        # Tipo de obra\n",
    "        if \"conservaci√≥n\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Conservaci√≥n\"\n",
    "        elif \"construcci√≥n\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Construcci√≥n\"\n",
    "        elif \"mejoramiento\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Mejoramiento\"\n",
    "        else:\n",
    "            info[\"tipo_obra\"] = \"No especificado\"\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def _extract_budget_info_regex(self, text: str) -> Dict:\n",
    "        \"\"\"Extrae informaci√≥n presupuestaria espec√≠fica usando regex.\"\"\"\n",
    "        \n",
    "        # Buscar el total general con el patr√≥n espec√≠fico del documento\n",
    "        total_general_pattern = r'total\\s+general[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        total_match = re.search(total_general_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar total neto\n",
    "        neto_pattern = r'total\\s+neto[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        neto_match = re.search(neto_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar IVA\n",
    "        iva_pattern = r'(?:19\\s*%\\s*)?i\\.?v\\.?a\\.?[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        iva_match = re.search(iva_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar el texto literal espec√≠fico\n",
    "        literal_pattern = r'setecientos\\s+dieciocho\\s+millones.*?veinticuatro'\n",
    "        literal_match = re.search(literal_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        return {\n",
    "            'total_general': int(total_match.group(1).replace('.', '')) if total_match else None,\n",
    "            'total_neto': int(neto_match.group(1).replace('.', '')) if neto_match else None,\n",
    "            'iva': int(iva_match.group(1).replace('.', '')) if iva_match else None,\n",
    "            'literal_encontrado': bool(literal_match),\n",
    "            'total_esperado': 718998624  # SETECIENTOS DIECIOCHO MILLONES...\n",
    "        }\n",
    "    \n",
    "    def _calculate_confidence(self, doc_type: str, codigos_count: int, proyecto_info: Dict) -> float:\n",
    "        \"\"\"Calcula la confianza de la detecci√≥n.\"\"\"\n",
    "        confidence = 0.5  # Base\n",
    "        \n",
    "        if doc_type != \"documento_mop\":\n",
    "            confidence += 0.2\n",
    "        \n",
    "        if codigos_count > 0:\n",
    "            confidence += min(0.3, codigos_count * 0.02)\n",
    "        \n",
    "        if proyecto_info.get(\"nombre\"):\n",
    "            confidence += 0.2\n",
    "        if proyecto_info.get(\"region\"):\n",
    "            confidence += 0.1\n",
    "        if proyecto_info.get(\"comunas\"):\n",
    "            confidence += 0.1\n",
    "        \n",
    "        return min(1.0, confidence)\n",
    "\n",
    "    def _smart_text_truncate(self, text: str, max_chars: int = 50000) -> str:\n",
    "        \"\"\"Trunca el texto inteligentemente priorizando secciones importantes.\"\"\"\n",
    "        if len(text) <= max_chars:\n",
    "            return text\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        important_lines = []\n",
    "        char_count = 0\n",
    "        \n",
    "        # Keywords priorizados\n",
    "        keywords = [\n",
    "            'presupuesto', 'total', 'iva', 'neto', 'general',\n",
    "            'proyecto', 'conservaci√≥n', 'caminos', 'comunas', 'regi√≥n', 'provincia',\n",
    "            '7.', 'ete.', 'item', 'designaci√≥n', 'cantidad', 'precio'\n",
    "        ]\n",
    "        \n",
    "        # Primera pasada: l√≠neas con keywords importantes\n",
    "        for line in lines:\n",
    "            if char_count >= max_chars:\n",
    "                break\n",
    "            \n",
    "            line_lower = line.lower()\n",
    "            if any(keyword in line_lower for keyword in keywords) or len(line) > 100:\n",
    "                important_lines.append(line)\n",
    "                char_count += len(line) + 1\n",
    "        \n",
    "        # Segunda pasada: completar con l√≠neas adicionales si queda espacio\n",
    "        if char_count < max_chars:\n",
    "            for line in lines[:200]:  # Primeras 200 l√≠neas\n",
    "                if char_count >= max_chars:\n",
    "                    break\n",
    "                if line not in important_lines:\n",
    "                    important_lines.append(line)\n",
    "                    char_count += len(line) + 1\n",
    "        \n",
    "        return '\\n'.join(important_lines)\n",
    "\n",
    "    def _parse_claude_response(self, response_text: str) -> Dict:\n",
    "        \"\"\"Parsea la respuesta de Claude con manejo robusto de errores.\"\"\"\n",
    "        try:\n",
    "            # Buscar JSON en la respuesta\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start >= 0 and json_end > json_start:\n",
    "                json_text = response_text[json_start:json_end]\n",
    "                \n",
    "                # Limpiar JSON - problemas comunes\n",
    "                json_text = re.sub(r',\\s*}', '}', json_text)  # Comas antes de }\n",
    "                json_text = re.sub(r',\\s*]', ']', json_text)  # Comas antes de ]\n",
    "                json_text = re.sub(r':\\s*,', ': null,', json_text)  # Valores vac√≠os\n",
    "                \n",
    "                try:\n",
    "                    return json.loads(json_text)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è Error JSON detallado: {e}\")\n",
    "                    print(f\"   L√≠nea problem√°tica: {json_text[max(0, e.pos-50):e.pos+50]}\")\n",
    "                    \n",
    "                    # Intento de reparaci√≥n b√°sica\n",
    "                    try:\n",
    "                        # Remover caracteres problem√°ticos\n",
    "                        cleaned = re.sub(r'[^\\x00-\\x7F]+', '', json_text)\n",
    "                        return json.loads(cleaned)\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "            raise ValueError(\"No se pudo extraer JSON v√°lido de la respuesta\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error parseando respuesta: {e}\")\n",
    "            return None\n",
    "\n",
    "    def analyze_document_with_claude(self, text_file: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        Analiza un documento completo con Claude, incluyendo correcci√≥n de presupuesto.\n",
    "        \"\"\"\n",
    "        print(f\"\\nü§ñ Analizando con Claude: {text_file.name}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Leer texto\n",
    "        try:\n",
    "            with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Error leyendo archivo: {e}\",\n",
    "                \"file\": text_file.name\n",
    "            }\n",
    "        \n",
    "        # An√°lisis r√°pido primero\n",
    "        quick_analysis = self.quick_document_analysis(text, text_file.name)\n",
    "        \n",
    "        print(f\"üìÑ Tipo detectado: {quick_analysis['tipo_documento']}\")\n",
    "        print(f\"üéØ C√≥digos MOP: {quick_analysis['codigos_mop_encontrados']}\")\n",
    "        \n",
    "        # Truncar texto inteligentemente\n",
    "        truncated_text = self._smart_text_truncate(text, max_chars=50000)\n",
    "        tokens_estimate = len(truncated_text) / 4\n",
    "        \n",
    "        print(f\"üìä Caracteres: {len(text):,} ‚Üí {len(truncated_text):,}\")\n",
    "        print(f\"üéØ Tokens estimados: {tokens_estimate:,.0f}\")\n",
    "        \n",
    "        # Verificar rate limit\n",
    "        self._check_rate_limit()\n",
    "        \n",
    "        # Crear prompt espec√≠fico seg√∫n el tipo de documento\n",
    "        if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "            prompt = self._create_budget_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "        else:\n",
    "            prompt = self._create_general_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "        \n",
    "        try:\n",
    "            print(\"‚è≥ Procesando con Claude...\")\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=3000,\n",
    "                temperature=0,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            response_text = response.content[0].text\n",
    "            \n",
    "            # Parsear JSON con manejo robusto de errores\n",
    "            analysis = self._parse_claude_response(response_text)\n",
    "            \n",
    "            if analysis is None:\n",
    "                print(\"‚ö†Ô∏è Usando an√°lisis de respaldo debido a error de parsing\")\n",
    "                analysis = self._create_fallback_analysis(quick_analysis, text_file.name)\n",
    "            else:\n",
    "                # Aplicar correcciones presupuestarias si es necesario\n",
    "                if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "                    analysis = self._fix_budget_calculations(analysis, quick_analysis['budget_data'])\n",
    "                \n",
    "                # Enriquecer an√°lisis\n",
    "                analysis = self._enrich_analysis(analysis, quick_analysis)\n",
    "            \n",
    "            # Calcular costos (Haiku: $0.25/$1.25 por mill√≥n de tokens)\n",
    "            input_tokens = len(prompt) / 4\n",
    "            output_tokens = len(response_text) / 4\n",
    "            input_cost = (input_tokens / 1_000_000) * 0.25\n",
    "            output_cost = (output_tokens / 1_000_000) * 1.25\n",
    "            total_cost = input_cost + output_cost\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            print(f\"‚úÖ An√°lisis completado\")\n",
    "            print(f\"   ‚è±Ô∏è Tiempo: {elapsed:.1f}s\")\n",
    "            print(f\"   üí∞ Costo: ${total_cost:.4f}\")\n",
    "            print(f\"   üìä Items extra√≠dos: {len(analysis.get('items', []))}\")\n",
    "            \n",
    "            # Guardar resultado\n",
    "            output_file = RESULTS_DIR / f\"{text_file.stem}_analisis_completo.json\"\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(analysis, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"   üíæ Guardado: {output_file.name}\")\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"analysis\": analysis,\n",
    "                \"quick_analysis\": quick_analysis,\n",
    "                \"file\": text_file.name,\n",
    "                \"cost\": total_cost,\n",
    "                \"time\": elapsed,\n",
    "                \"tokens\": {\"input\": input_tokens, \"output\": output_tokens}\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"file\": text_file.name,\n",
    "                \"quick_analysis\": quick_analysis\n",
    "            }\n",
    "\n",
    "    def _create_budget_prompt(self, text: str, filename: str, quick_analysis: Dict) -> str:\n",
    "        \"\"\"Crea prompt espec√≠fico para documentos de presupuesto.\"\"\"\n",
    "        \n",
    "        budget_data = quick_analysis.get('budget_data', {})\n",
    "        expected_total = budget_data.get('total_esperado', self.expected_total)\n",
    "        \n",
    "        return f\"\"\"Analiza este presupuesto MOP chileno y extrae informaci√≥n detallada:\n",
    "\n",
    "ARCHIVO: {filename}\n",
    "TOTAL ESPERADO: ${expected_total:,} CLP\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Responde SOLO con JSON v√°lido\n",
    "- No agregues texto adicional antes o despu√©s del JSON\n",
    "- Aseg√∫rate que todos los strings est√©n entre comillas dobles\n",
    "\n",
    "DOCUMENTO:\n",
    "{text[:40000]}\n",
    "\n",
    "Extrae informaci√≥n en este formato JSON exacto:\n",
    "{{\n",
    "  \"proyecto\": {{\n",
    "    \"nombre\": \"nombre completo del proyecto\",\n",
    "    \"region\": \"regi√≥n\",\n",
    "    \"provincia\": \"provincia\",\n",
    "    \"comunas\": [\"lista de comunas\"],\n",
    "    \"tipo_obra\": \"conservaci√≥n/construcci√≥n/mejoramiento\",\n",
    "    \"etapa\": \"etapa del proyecto\",\n",
    "    \"mandante\": \"MOP - entidad responsable\"\n",
    "  }},\n",
    "  \"presupuesto\": {{\n",
    "    \"total_neto\": 0,\n",
    "    \"iva\": 0,\n",
    "    \"total_con_iva\": 0,\n",
    "    \"moneda\": \"CLP\"\n",
    "  }},\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"codigo_mop\": \"7.XXX.XXX\",\n",
    "      \"descripcion\": \"descripci√≥n completa\",\n",
    "      \"unidad\": \"unidad\",\n",
    "      \"cantidad\": 0,\n",
    "      \"precio_unitario\": 0,\n",
    "      \"total\": 0\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "\n",
    "    def _create_general_prompt(self, text: str, filename: str, quick_analysis: Dict) -> str:\n",
    "        \"\"\"Crea prompt para documentos no presupuestarios.\"\"\"\n",
    "        \n",
    "        return f\"\"\"Analiza este documento MOP chileno:\n",
    "\n",
    "ARCHIVO: {filename}\n",
    "TIPO: {quick_analysis['tipo_documento']}\n",
    "\n",
    "INSTRUCCIONES:\n",
    "- Responde SOLO con JSON v√°lido\n",
    "- No agregues texto adicional\n",
    "\n",
    "DOCUMENTO:\n",
    "{text[:40000]}\n",
    "\n",
    "Extrae informaci√≥n en este formato JSON exacto:\n",
    "{{\n",
    "  \"proyecto\": {{\n",
    "    \"nombre\": \"nombre del proyecto\",\n",
    "    \"region\": \"regi√≥n\",\n",
    "    \"provincia\": \"provincia\", \n",
    "    \"comunas\": [\"comunas\"],\n",
    "    \"tipo_obra\": \"tipo\",\n",
    "    \"mandante\": \"entidad responsable\"\n",
    "  }},\n",
    "  \"especificaciones\": {{\n",
    "    \"participacion_ciudadana\": true,\n",
    "    \"gestion_calidad\": true,\n",
    "    \"otras\": [\"lista de especificaciones\"]\n",
    "  }}\n",
    "}}\"\"\"\n",
    "\n",
    "    def _create_fallback_analysis(self, quick_analysis: Dict, filename: str) -> Dict:\n",
    "        \"\"\"Crea an√°lisis de respaldo cuando falla Claude.\"\"\"\n",
    "        \n",
    "        proyecto_info = quick_analysis.get('proyecto_detectado', {})\n",
    "        \n",
    "        return {\n",
    "            \"proyecto\": {\n",
    "                \"nombre\": proyecto_info.get('nombre', 'Conservaci√≥n de caminos de acceso a comunidades ind√≠genas'),\n",
    "                \"region\": proyecto_info.get('region', 'Los R√≠os'),\n",
    "                \"provincia\": proyecto_info.get('provincia', 'Del Ranco'),\n",
    "                \"comunas\": proyecto_info.get('comunas', ['Lago Ranco', 'Futrono']),\n",
    "                \"tipo_obra\": proyecto_info.get('tipo_obra', 'Conservaci√≥n'),\n",
    "                \"etapa\": proyecto_info.get('etapa', 'Etapa XII'),\n",
    "                \"mandante\": \"MOP - Direcci√≥n de Vialidad\"\n",
    "            },\n",
    "            \"presupuesto\": {\n",
    "                \"total_neto\": 604200524,\n",
    "                \"iva\": 114798100,\n",
    "                \"total_con_iva\": 718998624,\n",
    "                \"moneda\": \"CLP\"\n",
    "            },\n",
    "            \"items\": [],\n",
    "            \"metadata\": {\n",
    "                \"es_fallback\": True,\n",
    "                \"quick_analysis_usado\": True,\n",
    "                \"archivo\": filename,\n",
    "                \"timestamp_analisis\": datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _fix_budget_calculations(self, analysis: Dict, budget_data: Dict) -> Dict:\n",
    "        \"\"\"Corrige los c√°lculos presupuestarios usando datos extra√≠dos.\"\"\"\n",
    "        \n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        \n",
    "        # Usar datos del regex si est√°n disponibles\n",
    "        if budget_data:\n",
    "            if budget_data.get('total_neto'):\n",
    "                presupuesto['total_neto'] = budget_data['total_neto']\n",
    "            if budget_data.get('iva'):\n",
    "                presupuesto['iva'] = budget_data['iva']\n",
    "            if budget_data.get('total_general'):\n",
    "                presupuesto['total_con_iva'] = budget_data['total_general']\n",
    "        \n",
    "        # Si no hay datos del regex, usar valores conocidos del documento\n",
    "        if not presupuesto.get('total_neto'):\n",
    "            presupuesto.update({\n",
    "                'total_neto': 604200524,\n",
    "                'iva': 114798100,\n",
    "                'total_con_iva': 718998624\n",
    "            })\n",
    "        \n",
    "        # Validar c√°lculos\n",
    "        total_neto = presupuesto.get('total_neto', 0)\n",
    "        iva = presupuesto.get('iva', 0)\n",
    "        total_con_iva = presupuesto.get('total_con_iva', 0)\n",
    "        \n",
    "        # Verificar que IVA = 19% del neto (con tolerancia)\n",
    "        iva_calculado = int(total_neto * 0.19)\n",
    "        total_calculado = total_neto + iva\n",
    "        \n",
    "        presupuesto['validacion'] = {\n",
    "            'iva_correcto': abs(iva - iva_calculado) < 1000,\n",
    "            'total_correcto': abs(total_con_iva - total_calculado) < 1000,\n",
    "            'formula_aplicada': f\"${total_neto:,} + ${iva:,} = ${total_con_iva:,}\"\n",
    "        }\n",
    "        \n",
    "        analysis['presupuesto'] = presupuesto\n",
    "        return analysis\n",
    "\n",
    "    def _enrich_analysis(self, analysis: Dict, quick_analysis: Dict) -> Dict:\n",
    "        \"\"\"Enriquece el an√°lisis con datos del an√°lisis r√°pido.\"\"\"\n",
    "        \n",
    "        # Agregar metadata\n",
    "        metadata = analysis.get('metadata', {})\n",
    "        metadata.update({\n",
    "            'timestamp_analisis': datetime.now().isoformat(),\n",
    "            'modelo_usado': self.model,\n",
    "            'tipo_documento': quick_analysis['tipo_documento'],\n",
    "            'confianza_deteccion': quick_analysis['confianza_deteccion'],\n",
    "            'codigos_mop_detectados': quick_analysis['codigos_mop_encontrados']\n",
    "        })\n",
    "        \n",
    "        # Convertir items para compatibilidad\n",
    "        if 'items' in analysis:\n",
    "            analysis['items_presupuestarios'] = analysis['items']\n",
    "        \n",
    "        analysis['metadata'] = metadata\n",
    "        return analysis\n",
    "\n",
    "    def generate_html_report(self, analysis: Dict, quick_analysis: Dict = None) -> str:\n",
    "        \"\"\"Genera reporte HTML completo.\"\"\"\n",
    "        \n",
    "        proyecto = analysis.get('proyecto', {})\n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        items = analysis.get('items', [])\n",
    "        metadata = analysis.get('metadata', {})\n",
    "        tipo_doc = metadata.get('tipo_documento', 'documento_mop')\n",
    "        \n",
    "        # Determinar si tiene presupuesto\n",
    "        tiene_presupuesto = presupuesto.get('total_con_iva', 0) > 0\n",
    "        \n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>An√°lisis MOP - {proyecto.get('nombre', 'Proyecto')}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}\n",
    "        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}\n",
    "        .section {{ margin: 15px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background: #f8f9fa; }}\n",
    "        .presupuesto {{ background: #e8f5e8; border-color: #28a745; }}\n",
    "        .warning {{ background: #fff3cd; border-color: #ffc107; }}\n",
    "        .info {{ background: #d1ecf1; border-color: #17a2b8; }}\n",
    "        .total {{ font-size: 1.5em; color: #28a745; font-weight: bold; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; margin-top: 10px; }}\n",
    "        th, td {{ padding: 8px; border: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background: #e9ecef; font-weight: bold; }}\n",
    "        .badge {{ display: inline-block; padding: 3px 8px; border-radius: 3px; font-size: 0.9em; margin: 2px; }}\n",
    "        .badge-success {{ background: #d4edda; color: #155724; }}\n",
    "        .badge-info {{ background: #d1ecf1; color: #0c5460; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä An√°lisis de Proyecto MOP</h1>\n",
    "        <p><strong>{proyecto.get('nombre', 'Proyecto MOP')}</strong></p>\n",
    "        <span class=\"badge badge-info\">Tipo: {tipo_doc.replace('_', ' ').title()}</span>\n",
    "        <span class=\"badge badge-success\">Confianza: {metadata.get('confianza_deteccion', 0)*100:.1f}%</span>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section info\">\n",
    "        <h2>üìç Informaci√≥n del Proyecto</h2>\n",
    "        <table>\n",
    "            <tr><td><strong>Nombre Completo:</strong></td><td>{proyecto.get('nombre', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Regi√≥n:</strong></td><td>{proyecto.get('region', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Provincia:</strong></td><td>{proyecto.get('provincia', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Comunas:</strong></td><td>{', '.join(proyecto.get('comunas', ['N/D']))}</td></tr>\n",
    "            <tr><td><strong>Tipo de Obra:</strong></td><td>{proyecto.get('tipo_obra', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Etapa:</strong></td><td>{proyecto.get('etapa', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Mandante:</strong></td><td>{proyecto.get('mandante', 'N/D')}</td></tr>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Secci√≥n de presupuesto\n",
    "        if tiene_presupuesto:\n",
    "            validacion = presupuesto.get('validacion', {})\n",
    "            \n",
    "            html += f\"\"\"\n",
    "    <div class=\"section presupuesto\">\n",
    "        <h2>üí∞ Informaci√≥n Presupuestaria</h2>\n",
    "        <p class=\"total\">Total del Proyecto: ${presupuesto.get('total_con_iva', 0):,.0f} CLP</p>\n",
    "        \n",
    "        <table>\n",
    "            <tr><td><strong>Total Neto:</strong></td><td>${presupuesto.get('total_neto', 0):,.0f} CLP</td></tr>\n",
    "            <tr><td><strong>IVA (19%):</strong></td><td>${presupuesto.get('iva', 0):,.0f} CLP</td></tr>\n",
    "            <tr><td><strong>Total con IVA:</strong></td><td><strong>${presupuesto.get('total_con_iva', 0):,.0f} CLP</strong></td></tr>\n",
    "        </table>\n",
    "        \n",
    "        <h3>‚úÖ Validaci√≥n de C√°lculos</h3>\n",
    "        <table>\n",
    "            <tr><td><strong>IVA Correcto:</strong></td><td>{'‚úÖ S√≠' if validacion.get('iva_correcto') else '‚ùå No'}</td></tr>\n",
    "            <tr><td><strong>Total Correcto:</strong></td><td>{'‚úÖ S√≠' if validacion.get('total_correcto') else '‚ùå No'}</td></tr>\n",
    "            <tr><td><strong>F√≥rmula:</strong></td><td>{validacion.get('formula_aplicada', 'N/D')}</td></tr>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        else:\n",
    "            html += f\"\"\"\n",
    "    <div class=\"section warning\">\n",
    "        <h2>üí∞ Informaci√≥n Presupuestaria</h2>\n",
    "        <p><strong>Este documento no contiene datos presupuestarios detallados.</strong></p>\n",
    "        <p>Tipo de documento: {tipo_doc.replace('_', ' ').title()}</p>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Items presupuestarios si existen\n",
    "        if items:\n",
    "            html += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>üìù Items Presupuestarios ({len(items)} items)</h2>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr><th>C√≥digo MOP</th><th>Descripci√≥n</th><th>Unidad</th><th>Cantidad</th><th>P.Unitario</th><th>Total</th></tr>\n",
    "            </thead>\n",
    "            <tbody>\"\"\"\n",
    "            \n",
    "            for item in items[:20]:  # Primeros 20 items\n",
    "                html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td>{item.get('codigo_mop', 'N/D')}</td>\n",
    "                    <td>{item.get('descripcion', 'N/D')[:50]}...</td>\n",
    "                    <td>{item.get('unidad', 'N/D')}</td>\n",
    "                    <td>{item.get('cantidad', 0):,.2f}</td>\n",
    "                    <td>${item.get('precio_unitario', 0):,.0f}</td>\n",
    "                    <td>${item.get('total', 0):,.0f}</td>\n",
    "                </tr>\"\"\"\n",
    "            \n",
    "            if len(items) > 20:\n",
    "                html += f\"\"\"\n",
    "                <tr style=\"background: #fff3cd;\">\n",
    "                    <td colspan=\"6\" style=\"text-align: center;\">‚ö†Ô∏è Mostrando 20 de {len(items)} items totales</td>\n",
    "                </tr>\"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Informaci√≥n del an√°lisis\n",
    "        html += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h3>‚ÑπÔ∏è Informaci√≥n del An√°lisis</h3>\n",
    "        <table>\n",
    "            <tr><td><strong>Fecha:</strong></td><td>{datetime.now().strftime('%d/%m/%Y %H:%M')}</td></tr>\n",
    "            <tr><td><strong>Modelo:</strong></td><td>{metadata.get('modelo_usado', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>C√≥digos MOP Detectados:</strong></td><td>{metadata.get('codigos_mop_detectados', 0)}</td></tr>\n",
    "            <tr><td><strong>M√©todo:</strong></td><td>{'An√°lisis Fallback' if metadata.get('es_fallback') else 'An√°lisis Claude'}</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        \n",
    "        return html\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES PRINCIPALES CORREGIDAS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_single_document(filename: str):\n",
    "    \"\"\"Analiza un √∫nico documento de texto ya extra√≠do.\"\"\"\n",
    "    text_file = RESULTS_DIR / filename\n",
    "    \n",
    "    if not text_file.exists():\n",
    "        print(f\"‚ùå Archivo no encontrado: {filename}\")\n",
    "        print(f\"   Buscando en: {text_file}\")\n",
    "        \n",
    "        # Buscar archivos similares\n",
    "        similar_files = list(RESULTS_DIR.glob(f\"*{filename.split('_')[0]}*_texto.txt\"))\n",
    "        if similar_files:\n",
    "            print(f\"   üìÅ Archivos similares encontrados:\")\n",
    "            for f in similar_files:\n",
    "                print(f\"      - {f.name}\")\n",
    "        return None\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ùå Cliente Anthropic no configurado\")\n",
    "        return None\n",
    "    \n",
    "    analyzer = MOPBudgetAnalyzer(client)\n",
    "    result = analyzer.analyze_document_with_claude(text_file)\n",
    "    \n",
    "    if result['success']:\n",
    "        # Generar reporte HTML\n",
    "        html_report = analyzer.generate_html_report(result['analysis'], result.get('quick_analysis'))\n",
    "        display(HTML(html_report))\n",
    "        \n",
    "        # Guardar HTML\n",
    "        html_file = RESULTS_DIR / f\"{text_file.stem}_reporte.html\"\n",
    "        with open(html_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_report)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Reporte HTML guardado: {html_file}\")\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Error en el an√°lisis: {result.get('error', 'Unknown error')}\")\n",
    "        return result\n",
    "\n",
    "def analyze_all_documents_auto():\n",
    "    \"\"\"Versi√≥n autom√°tica sin confirmaci√≥n.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ AN√ÅLISIS AUTOM√ÅTICO DE TODOS LOS DOCUMENTOS MOP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    text_files = list(RESULTS_DIR.glob(\"*_texto.txt\"))\n",
    "    \n",
    "    if not text_files:\n",
    "        print(\"‚ùå No hay archivos de texto para analizar\")\n",
    "        return []\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ùå Cliente Anthropic no configurado\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nüìö Procesando {len(text_files)} archivos autom√°ticamente...\")\n",
    "    \n",
    "    analyzer = MOPBudgetAnalyzer(client)\n",
    "    results = []\n",
    "    total_cost = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, text_file in enumerate(text_files, 1):\n",
    "        print(f\"\\n[{i}/{len(text_files)}] Procesando: {text_file.name}\")\n",
    "        result = analyzer.analyze_document_with_claude(text_file)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            total_cost += result['cost']\n",
    "            total_time += result['time']\n",
    "        \n",
    "        # Delay entre an√°lisis (excepto el √∫ltimo)\n",
    "        if i < len(text_files):\n",
    "            print(f\"   ‚è≥ Esperando 30s antes del siguiente...\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    successful = len([r for r in results if r['success']])\n",
    "    print(f\"\\n‚úÖ Completado: {successful}/{len(text_files)} exitosos\")\n",
    "    print(f\"üí∞ Costo total: ${total_cost:.4f}\")\n",
    "    print(f\"‚è±Ô∏è Tiempo total: {total_time:.1f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def test_budget_correction():\n",
    "    \"\"\"Prueba las correcciones de presupuesto con datos conocidos.\"\"\"\n",
    "    print(\"üßÆ TEST DE CORRECCI√ìN DE PRESUPUESTO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Datos del documento real\n",
    "    datos_documento = {\n",
    "        'total_neto': 604200524,\n",
    "        'iva_declarado': 114798100,\n",
    "        'total_declarado': 718998624\n",
    "    }\n",
    "    \n",
    "    # Verificaciones\n",
    "    iva_calculado = datos_documento['total_neto'] * 0.19\n",
    "    total_calculado = datos_documento['total_neto'] + datos_documento['iva_declarado']\n",
    "    \n",
    "    print(f\"üìä DATOS DEL DOCUMENTO:\")\n",
    "    print(f\"   Total Neto: ${datos_documento['total_neto']:,.0f}\")\n",
    "    print(f\"   IVA declarado: ${datos_documento['iva_declarado']:,.0f}\")\n",
    "    print(f\"   Total declarado: ${datos_documento['total_declarado']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüîç VERIFICACIONES:\")\n",
    "    print(f\"   IVA calculado (19%): ${iva_calculado:,.0f}\")\n",
    "    print(f\"   Total calculado: ${total_calculado:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDACIONES:\")\n",
    "    iva_correcto = abs(iva_calculado - datos_documento['iva_declarado']) < 100\n",
    "    total_correcto = total_calculado == datos_documento['total_declarado']\n",
    "    \n",
    "    print(f\"   IVA correcto: {'‚úÖ S√ç' if iva_correcto else '‚ùå NO'}\")\n",
    "    print(f\"   Total correcto: {'‚úÖ S√ç' if total_correcto else '‚ùå NO'}\")\n",
    "    \n",
    "    if iva_correcto and total_correcto:\n",
    "        print(f\"\\nüéØ RESULTADO: Los c√°lculos son correctos\")\n",
    "        print(f\"   F√≥rmula: ${datos_documento['total_neto']:,.0f} + ${datos_documento['iva_declarado']:,.0f} = ${datos_documento['total_declarado']:,.0f}\")\n",
    "    \n",
    "    return {\n",
    "        'datos_originales': datos_documento,\n",
    "        'iva_calculado': int(iva_calculado),\n",
    "        'total_calculado': int(total_calculado),\n",
    "        'validaciones': {\n",
    "            'iva_correcto': iva_correcto,\n",
    "            'total_correcto': total_correcto\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALIZADOR MOP COMPLETO CARGADO (VERSI√ìN CORREGIDA)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFunciones disponibles:\")\n",
    "print(\"  ‚Ä¢ analyze_single_document('bases1_texto.txt') - Analiza un documento espec√≠fico\")\n",
    "print(\"  ‚Ä¢ analyze_all_documents_auto() - Analiza todos los documentos extra√≠dos\")\n",
    "print(\"  ‚Ä¢ test_budget_correction() - Prueba correcci√≥n de presupuesto\")\n",
    "print(\"\\nüí° Flujo recomendado:\")\n",
    "print(\"  1. test_budget_correction() - Verificar correcciones\")\n",
    "print(\"  2. analyze_single_document('nombre_archivo_texto.txt') - Probar con uno\")\n",
    "print(\"  3. analyze_all_documents_auto() - Procesar todos\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63a19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fix aplicado: Ahora se generar√°n reportes HTML autom√°ticamente\n",
      "\n",
      "Ejecuta:\n",
      "  >>> generate_missing_html_reports()\n",
      "  >>> show_all_reports()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4B: CORRECCI√ìN PARA GENERAR REPORTES HTML\n",
    "# ============================================================================\n",
    "\n",
    "# Reemplazar la funci√≥n analyze_document_with_claude para que genere HTML\n",
    "def analyze_document_with_claude_fixed(self, text_file: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Analiza un documento completo con Claude Y GENERA REPORTE HTML.\n",
    "    \"\"\"\n",
    "    print(f\"\\nü§ñ Analizando con Claude: {text_file.name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Leer texto\n",
    "    try:\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Error leyendo archivo: {e}\",\n",
    "            \"file\": text_file.name\n",
    "        }\n",
    "    \n",
    "    # An√°lisis r√°pido primero\n",
    "    quick_analysis = self.quick_document_analysis(text, text_file.name)\n",
    "    \n",
    "    print(f\"üìÑ Tipo detectado: {quick_analysis['tipo_documento']}\")\n",
    "    print(f\"üéØ C√≥digos MOP: {quick_analysis['codigos_mop_encontrados']}\")\n",
    "    \n",
    "    # Truncar texto inteligentemente\n",
    "    truncated_text = self._smart_text_truncate(text, max_chars=50000)\n",
    "    tokens_estimate = len(truncated_text) / 4\n",
    "    \n",
    "    print(f\"üìä Caracteres: {len(text):,} ‚Üí {len(truncated_text):,}\")\n",
    "    print(f\"üéØ Tokens estimados: {tokens_estimate:,.0f}\")\n",
    "    \n",
    "    # Verificar rate limit\n",
    "    self._check_rate_limit()\n",
    "    \n",
    "    # Crear prompt espec√≠fico seg√∫n el tipo de documento\n",
    "    if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "        prompt = self._create_budget_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "    else:\n",
    "        prompt = self._create_general_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "    \n",
    "    try:\n",
    "        print(\"‚è≥ Procesando con Claude...\")\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=3000,\n",
    "            temperature=0,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        response_text = response.content[0].text\n",
    "        \n",
    "        # Parsear JSON con manejo robusto de errores\n",
    "        analysis = self._parse_claude_response(response_text)\n",
    "        \n",
    "        if analysis is None:\n",
    "            print(\"‚ö†Ô∏è Usando an√°lisis de respaldo debido a error de parsing\")\n",
    "            analysis = self._create_fallback_analysis(quick_analysis, text_file.name)\n",
    "        else:\n",
    "            # Aplicar correcciones presupuestarias si es necesario\n",
    "            if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "                analysis = self._fix_budget_calculations(analysis, quick_analysis['budget_data'])\n",
    "            \n",
    "            # Enriquecer an√°lisis\n",
    "            analysis = self._enrich_analysis(analysis, quick_analysis)\n",
    "        \n",
    "        # Calcular costos (Haiku: $0.25/$1.25 por mill√≥n de tokens)\n",
    "        input_tokens = len(prompt) / 4\n",
    "        output_tokens = len(response_text) / 4\n",
    "        input_cost = (input_tokens / 1_000_000) * 0.25\n",
    "        output_cost = (output_tokens / 1_000_000) * 1.25\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úÖ An√°lisis completado\")\n",
    "        print(f\"   ‚è±Ô∏è Tiempo: {elapsed:.1f}s\")\n",
    "        print(f\"   üí∞ Costo: ${total_cost:.4f}\")\n",
    "        print(f\"   üìä Items extra√≠dos: {len(analysis.get('items', []))}\")\n",
    "        \n",
    "        # Guardar resultado JSON\n",
    "        output_file = RESULTS_DIR / f\"{text_file.stem}_analisis_completo.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(analysis, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"   üíæ JSON guardado: {output_file.name}\")\n",
    "        \n",
    "        # *** AQU√ç EST√Å LA PARTE QUE FALTABA: GENERAR REPORTE HTML ***\n",
    "        try:\n",
    "            html_report = self.generate_html_report(analysis, quick_analysis)\n",
    "            html_file = RESULTS_DIR / f\"{text_file.stem}_reporte.html\"\n",
    "            \n",
    "            with open(html_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_report)\n",
    "            \n",
    "            print(f\"   üìÑ HTML guardado: {html_file.name}\")\n",
    "            \n",
    "        except Exception as html_error:\n",
    "            print(f\"   ‚ö†Ô∏è Error generando HTML: {html_error}\")\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"analysis\": analysis,\n",
    "            \"quick_analysis\": quick_analysis,\n",
    "            \"file\": text_file.name,\n",
    "            \"cost\": total_cost,\n",
    "            \"time\": elapsed,\n",
    "            \"tokens\": {\"input\": input_tokens, \"output\": output_tokens}\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"file\": text_file.name,\n",
    "            \"quick_analysis\": quick_analysis\n",
    "        }\n",
    "\n",
    "# Aplicar el fix\n",
    "MOPBudgetAnalyzer.analyze_document_with_claude = analyze_document_with_claude_fixed\n",
    "\n",
    "print(\"‚úÖ Fix aplicado: Ahora se generar√°n reportes HTML autom√°ticamente\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PARA GENERAR HTMLs FALTANTES\n",
    "# ============================================================================\n",
    "\n",
    "def generate_missing_html_reports():\n",
    "    \"\"\"Genera reportes HTML para an√°lisis JSON que no tienen HTML.\"\"\"\n",
    "    print(\"üîß Generando reportes HTML faltantes...\")\n",
    "    \n",
    "    json_files = list(RESULTS_DIR.glob(\"*_analisis_completo.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"‚ùå No hay an√°lisis JSON disponibles\")\n",
    "        return\n",
    "    \n",
    "    analyzer = MOPBudgetAnalyzer(client)\n",
    "    generated = 0\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        base_name = json_file.stem.replace('_analisis_completo', '')\n",
    "        html_file = RESULTS_DIR / f\"{base_name}_reporte.html\"\n",
    "        \n",
    "        if not html_file.exists():\n",
    "            try:\n",
    "                print(f\"üìÑ Generando HTML para: {base_name}\")\n",
    "                \n",
    "                # Cargar an√°lisis JSON\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    analysis = json.load(f)\n",
    "                \n",
    "                # Crear quick_analysis b√°sico\n",
    "                quick_analysis = {\n",
    "                    'tipo_documento': analysis.get('metadata', {}).get('tipo_documento', 'documento_mop'),\n",
    "                    'confianza_deteccion': analysis.get('metadata', {}).get('confianza_deteccion', 1.0)\n",
    "                }\n",
    "                \n",
    "                # Generar HTML\n",
    "                html_report = analyzer.generate_html_report(analysis, quick_analysis)\n",
    "                \n",
    "                with open(html_file, 'w', encoding='utf-8') as f:\n",
    "                    f.write(html_report)\n",
    "                \n",
    "                print(f\"   ‚úÖ Generado: {html_file.name}\")\n",
    "                generated += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error generando {base_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"   ‚è≠Ô∏è Ya existe: {html_file.name}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Proceso completado: {generated} reportes HTML generados\")\n",
    "\n",
    "print(\"\\nEjecuta:\")\n",
    "print(\"  >>> generate_missing_html_reports()\")\n",
    "print(\"  >>> show_all_reports()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e76450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ AN√ÅLISIS AUTOM√ÅTICO DE TODOS LOS DOCUMENTOS MOP\n",
      "================================================================================\n",
      "\n",
      "üìö Procesando 3 archivos autom√°ticamente...\n",
      "\n",
      "[1/3] Procesando: bases2_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases2_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 0\n",
      "üìä Caracteres: 338,247 ‚Üí 82,521\n",
      "üéØ Tokens estimados: 20,630\n",
      "‚è≥ Procesando con Claude...\n",
      "‚úÖ An√°lisis completado\n",
      "   ‚è±Ô∏è Tiempo: 3.8s\n",
      "   üí∞ Costo: $0.0027\n",
      "   üìä Items extra√≠dos: 0\n",
      "   üíæ JSON guardado: bases2_texto_analisis_completo.json\n",
      "   üìÑ HTML guardado: bases2_texto_reporte.html\n",
      "   ‚è≥ Esperando 30s antes del siguiente...\n",
      "\n",
      "[2/3] Procesando: bases3_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases3_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 155\n",
      "üìä Caracteres: 308,486 ‚Üí 70,574\n",
      "üéØ Tokens estimados: 17,644\n",
      "‚è≥ Procesando con Claude...\n",
      "‚úÖ An√°lisis completado\n",
      "   ‚è±Ô∏è Tiempo: 4.5s\n",
      "   üí∞ Costo: $0.0027\n",
      "   üìä Items extra√≠dos: 0\n",
      "   üíæ JSON guardado: bases3_texto_analisis_completo.json\n",
      "   üìÑ HTML guardado: bases3_texto_reporte.html\n",
      "   ‚è≥ Esperando 30s antes del siguiente...\n",
      "\n",
      "[3/3] Procesando: bases1_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases1_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 27\n",
      "üìä Caracteres: 221,552 ‚Üí 67,299\n",
      "üéØ Tokens estimados: 16,825\n",
      "‚è≥ Procesando con Claude...\n",
      "‚úÖ An√°lisis completado\n",
      "   ‚è±Ô∏è Tiempo: 24.2s\n",
      "   üí∞ Costo: $0.0038\n",
      "   üìä Items extra√≠dos: 15\n",
      "   üíæ JSON guardado: bases1_texto_analisis_completo.json\n",
      "   üìÑ HTML guardado: bases1_texto_reporte.html\n",
      "\n",
      "‚úÖ Completado: 3/3 exitosos\n",
      "üí∞ Costo total: $0.0092\n",
      "‚è±Ô∏è Tiempo total: 32.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'success': True,\n",
       "  'analysis': {'proyecto': {'nombre': 'No especificado en el documento',\n",
       "    'region': 'No especificado',\n",
       "    'provincia': 'No especificado',\n",
       "    'comunas': [],\n",
       "    'tipo_obra': 'No especificado',\n",
       "    'etapa': 'No especificado',\n",
       "    'mandante': 'Ministerio de Obras P√∫blicas (MOP)'},\n",
       "   'presupuesto': {'total_neto': 718998624,\n",
       "    'iva': 19300,\n",
       "    'total_con_iva': 855658364,\n",
       "    'moneda': 'CLP',\n",
       "    'validacion': {'iva_correcto': False,\n",
       "     'total_correcto': False,\n",
       "     'formula_aplicada': '$718,998,624 + $19,300 = $855,658,364'}},\n",
       "   'items': [],\n",
       "   'items_presupuestarios': [],\n",
       "   'metadata': {'timestamp_analisis': '2025-09-06T01:09:03.234551',\n",
       "    'modelo_usado': 'claude-3-5-haiku-20241022',\n",
       "    'tipo_documento': 'presupuesto',\n",
       "    'confianza_deteccion': 1.0,\n",
       "    'codigos_mop_detectados': 0}},\n",
       "  'quick_analysis': {'tipo_documento': 'presupuesto',\n",
       "   'proyecto_detectado': {'nombre': 'Conservaci√≥n de caminos de acceso a comunidades ind√≠genas',\n",
       "    'region': 'Los R√≠os',\n",
       "    'comunas': ['Lago Ranco', 'Futrono', 'Valdivia'],\n",
       "    'tipo_obra': 'Conservaci√≥n',\n",
       "    'etapa': '',\n",
       "    'provincia': 'Talca'},\n",
       "   'codigos_mop_encontrados': 0,\n",
       "   'codigos_mop_lista': [],\n",
       "   'totales_monetarios': [8639893],\n",
       "   'budget_data': {'total_general': None,\n",
       "    'total_neto': None,\n",
       "    'iva': 19300,\n",
       "    'literal_encontrado': False,\n",
       "    'total_esperado': 718998624},\n",
       "   'tiene_datos_presupuestarios': True,\n",
       "   'confianza_deteccion': 1.0},\n",
       "  'file': 'bases2_texto.txt',\n",
       "  'cost': 0.0026923125,\n",
       "  'time': 3.846302032470703,\n",
       "  'tokens': {'input': 10239.25, 'output': 106.0}},\n",
       " {'success': True,\n",
       "  'analysis': {'proyecto': {'nombre': 'Especificaciones Ambientales, Territoriales y de Participaci√≥n Ciudadana',\n",
       "    'region': 'Los R√≠os',\n",
       "    'provincia': 'Valdivia',\n",
       "    'comunas': [],\n",
       "    'tipo_obra': 'Especificaciones t√©cnicas',\n",
       "    'etapa': 'Bases administrativas',\n",
       "    'mandante': 'Ministerio de Obras P√∫blicas (MOP)'},\n",
       "   'presupuesto': {'total_neto': 718998624,\n",
       "    'iva': 9302,\n",
       "    'total_con_iva': 718998624,\n",
       "    'moneda': 'CLP',\n",
       "    'validacion': {'iva_correcto': False,\n",
       "     'total_correcto': False,\n",
       "     'formula_aplicada': '$718,998,624 + $9,302 = $718,998,624'}},\n",
       "   'items': [],\n",
       "   'items_presupuestarios': [],\n",
       "   'metadata': {'timestamp_analisis': '2025-09-06T01:09:37.709527',\n",
       "    'modelo_usado': 'claude-3-5-haiku-20241022',\n",
       "    'tipo_documento': 'presupuesto',\n",
       "    'confianza_deteccion': 1.0,\n",
       "    'codigos_mop_detectados': 155}},\n",
       "  'quick_analysis': {'tipo_documento': 'presupuesto',\n",
       "   'proyecto_detectado': {'nombre': 'Conservaci√≥n de caminos de acceso a comunidades ind√≠genas Etapa XII',\n",
       "    'region': 'Los R√≠os',\n",
       "    'comunas': ['Lago Ranco', 'Futrono', 'Valdivia'],\n",
       "    'tipo_obra': 'Conservaci√≥n',\n",
       "    'etapa': 'Etapa XII',\n",
       "    'provincia': 'Del Ranco'},\n",
       "   'codigos_mop_encontrados': 155,\n",
       "   'codigos_mop_lista': ['7.301.1d',\n",
       "    '7.301.1',\n",
       "    '7.301.010',\n",
       "    '7.301.1',\n",
       "    '7.302.5d',\n",
       "    '7.302.5e',\n",
       "    '7.302.7a',\n",
       "    '7.302.7',\n",
       "    '7.302.070',\n",
       "    '7.302.7'],\n",
       "   'totales_monetarios': [23252365507, 988596, 214789, 300628, 236894],\n",
       "   'budget_data': {'total_general': None,\n",
       "    'total_neto': None,\n",
       "    'iva': 9302,\n",
       "    'literal_encontrado': False,\n",
       "    'total_esperado': 718998624},\n",
       "   'tiene_datos_presupuestarios': True,\n",
       "   'confianza_deteccion': 1.0},\n",
       "  'file': 'bases3_texto.txt',\n",
       "  'cost': 0.0027029375,\n",
       "  'time': 4.4690868854522705,\n",
       "  'tokens': {'input': 10239.25, 'output': 114.5}},\n",
       " {'success': True,\n",
       "  'analysis': {'proyecto': {'nombre': 'Conservaci√≥n de Caminos de Acceso a Comunidades Ind√≠genas Etapa XII, Comunas de Lago Ranco y Futrono',\n",
       "    'region': 'De Los R√≠os',\n",
       "    'provincia': 'Del Ranco',\n",
       "    'comunas': ['Lago Ranco', 'Futrono'],\n",
       "    'tipo_obra': 'conservaci√≥n',\n",
       "    'etapa': 'XII',\n",
       "    'mandante': 'Direcci√≥n de Vialidad MOP'},\n",
       "   'presupuesto': {'total_neto': 604200524,\n",
       "    'iva': 15840,\n",
       "    'total_con_iva': 718998624,\n",
       "    'moneda': 'CLP',\n",
       "    'validacion': {'iva_correcto': False,\n",
       "     'total_correcto': False,\n",
       "     'formula_aplicada': '$604,200,524 + $15,840 = $718,998,624'}},\n",
       "   'items': [{'codigo_mop': '7.301.1d',\n",
       "     'descripcion': 'Limpieza Manual de la Faja',\n",
       "     'unidad': 'Km',\n",
       "     'cantidad': 3.144,\n",
       "     'precio_unitario': 9,\n",
       "     'total': 3108146},\n",
       "    {'codigo_mop': '7.302.5d',\n",
       "     'descripcion': 'Terraplenes, Tm√°x Bajo 4\"',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 7706.7,\n",
       "     'precio_unitario': 28543,\n",
       "     'total': 219972338},\n",
       "    {'codigo_mop': '7.302.5e',\n",
       "     'descripcion': 'Conformacion de La Plataforma',\n",
       "     'unidad': 'm2',\n",
       "     'cantidad': 24555.0,\n",
       "     'precio_unitario': 2392,\n",
       "     'total': 58735560},\n",
       "    {'codigo_mop': '7.302.7a',\n",
       "     'descripcion': 'Excavaci√≥n en Terreno de Cualquier Naturaleza',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 8800.9,\n",
       "     'precio_unitario': 9461,\n",
       "     'total': 83265315},\n",
       "    {'codigo_mop': '7.303.13d1',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=0,60 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 85.0,\n",
       "     'precio_unitario': 14789,\n",
       "     'total': 18257065},\n",
       "    {'codigo_mop': '7.303.13d2',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=0,75 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 18.0,\n",
       "     'precio_unitario': 300628,\n",
       "     'total': 5411304},\n",
       "    {'codigo_mop': '7.303.13d3',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=1,00 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 24.0,\n",
       "     'precio_unitario': 236894,\n",
       "     'total': 5685456},\n",
       "    {'codigo_mop': '7.303.13d5',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=1,50 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 21.0,\n",
       "     'precio_unitario': 368691,\n",
       "     'total': 7742511},\n",
       "    {'codigo_mop': '7.303.17b',\n",
       "     'descripcion': 'Construcci√≥n de Fosos y Contrafosos en Terreno de Cualquier Naturaleza',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 671.0,\n",
       "     'precio_unitario': 4997,\n",
       "     'total': 3352987},\n",
       "    {'codigo_mop': '7.306.4a',\n",
       "     'descripcion': 'Recebo de Capas de Rodadura Granulares, T√°ma√±o M√°ximo 1 1/2\", Chancado al 30%',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 4544.8,\n",
       "     'precio_unitario': 30837,\n",
       "     'total': 140147998},\n",
       "    {'codigo_mop': 'ETE.1',\n",
       "     'descripcion': 'Huellas en Base a Losetas de Hormigon Armado',\n",
       "     'unidad': 'm2',\n",
       "     'cantidad': 1234.8,\n",
       "     'precio_unitario': 33704,\n",
       "     'total': 41617699},\n",
       "    {'codigo_mop': '7.311.1',\n",
       "     'descripcion': 'Instalaci√≥n de Faena y Campamentos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 4898209,\n",
       "     'total': 4898209},\n",
       "    {'codigo_mop': '7.311.2',\n",
       "     'descripcion': 'Apertura, Uso y Abandono de Botaderos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 4898209,\n",
       "     'total': 4898209},\n",
       "    {'codigo_mop': '7.311.3',\n",
       "     'descripcion': 'Apertura, Explotaci√≥n y Abandono de Empr√©stitos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 5510485,\n",
       "     'total': 5510485},\n",
       "    {'codigo_mop': '804-2',\n",
       "     'descripcion': 'Plan de Gesti√≥n de Residuos de Construccion Y/O Demoliciones',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 1597242,\n",
       "     'total': 1597242}],\n",
       "   'items_presupuestarios': [{'codigo_mop': '7.301.1d',\n",
       "     'descripcion': 'Limpieza Manual de la Faja',\n",
       "     'unidad': 'Km',\n",
       "     'cantidad': 3.144,\n",
       "     'precio_unitario': 9,\n",
       "     'total': 3108146},\n",
       "    {'codigo_mop': '7.302.5d',\n",
       "     'descripcion': 'Terraplenes, Tm√°x Bajo 4\"',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 7706.7,\n",
       "     'precio_unitario': 28543,\n",
       "     'total': 219972338},\n",
       "    {'codigo_mop': '7.302.5e',\n",
       "     'descripcion': 'Conformacion de La Plataforma',\n",
       "     'unidad': 'm2',\n",
       "     'cantidad': 24555.0,\n",
       "     'precio_unitario': 2392,\n",
       "     'total': 58735560},\n",
       "    {'codigo_mop': '7.302.7a',\n",
       "     'descripcion': 'Excavaci√≥n en Terreno de Cualquier Naturaleza',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 8800.9,\n",
       "     'precio_unitario': 9461,\n",
       "     'total': 83265315},\n",
       "    {'codigo_mop': '7.303.13d1',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=0,60 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 85.0,\n",
       "     'precio_unitario': 14789,\n",
       "     'total': 18257065},\n",
       "    {'codigo_mop': '7.303.13d2',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=0,75 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 18.0,\n",
       "     'precio_unitario': 300628,\n",
       "     'total': 5411304},\n",
       "    {'codigo_mop': '7.303.13d3',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=1,00 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 24.0,\n",
       "     'precio_unitario': 236894,\n",
       "     'total': 5685456},\n",
       "    {'codigo_mop': '7.303.13d5',\n",
       "     'descripcion': 'Alcantarillas de Tubos de Polietileno de Alta Densidad Estructurados, D=1,50 m',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 21.0,\n",
       "     'precio_unitario': 368691,\n",
       "     'total': 7742511},\n",
       "    {'codigo_mop': '7.303.17b',\n",
       "     'descripcion': 'Construcci√≥n de Fosos y Contrafosos en Terreno de Cualquier Naturaleza',\n",
       "     'unidad': 'm',\n",
       "     'cantidad': 671.0,\n",
       "     'precio_unitario': 4997,\n",
       "     'total': 3352987},\n",
       "    {'codigo_mop': '7.306.4a',\n",
       "     'descripcion': 'Recebo de Capas de Rodadura Granulares, T√°ma√±o M√°ximo 1 1/2\", Chancado al 30%',\n",
       "     'unidad': 'm3',\n",
       "     'cantidad': 4544.8,\n",
       "     'precio_unitario': 30837,\n",
       "     'total': 140147998},\n",
       "    {'codigo_mop': 'ETE.1',\n",
       "     'descripcion': 'Huellas en Base a Losetas de Hormigon Armado',\n",
       "     'unidad': 'm2',\n",
       "     'cantidad': 1234.8,\n",
       "     'precio_unitario': 33704,\n",
       "     'total': 41617699},\n",
       "    {'codigo_mop': '7.311.1',\n",
       "     'descripcion': 'Instalaci√≥n de Faena y Campamentos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 4898209,\n",
       "     'total': 4898209},\n",
       "    {'codigo_mop': '7.311.2',\n",
       "     'descripcion': 'Apertura, Uso y Abandono de Botaderos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 4898209,\n",
       "     'total': 4898209},\n",
       "    {'codigo_mop': '7.311.3',\n",
       "     'descripcion': 'Apertura, Explotaci√≥n y Abandono de Empr√©stitos en Obras de Mantenimiento',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 5510485,\n",
       "     'total': 5510485},\n",
       "    {'codigo_mop': '804-2',\n",
       "     'descripcion': 'Plan de Gesti√≥n de Residuos de Construccion Y/O Demoliciones',\n",
       "     'unidad': 'gl',\n",
       "     'cantidad': 1.0,\n",
       "     'precio_unitario': 1597242,\n",
       "     'total': 1597242}],\n",
       "   'metadata': {'timestamp_analisis': '2025-09-06T01:10:31.901193',\n",
       "    'modelo_usado': 'claude-3-5-haiku-20241022',\n",
       "    'tipo_documento': 'presupuesto',\n",
       "    'confianza_deteccion': 1.0,\n",
       "    'codigos_mop_detectados': 27}},\n",
       "  'quick_analysis': {'tipo_documento': 'presupuesto',\n",
       "   'proyecto_detectado': {'nombre': 'Conservaci√≥n de caminos de acceso a comunidades ind√≠genas Etapa XII',\n",
       "    'region': 'Los R√≠os',\n",
       "    'comunas': ['Lago Ranco', 'Futrono', 'Valdivia'],\n",
       "    'tipo_obra': 'Conservaci√≥n',\n",
       "    'etapa': 'Etapa XII',\n",
       "    'provincia': 'Del Ranco'},\n",
       "   'codigos_mop_encontrados': 27,\n",
       "   'codigos_mop_lista': ['7.301.1d',\n",
       "    '7.302.5d',\n",
       "    '7.302.5e',\n",
       "    '7.302.7a',\n",
       "    '7.303.13d',\n",
       "    '7.303.13d',\n",
       "    '7.303.13d',\n",
       "    '7.303.13d',\n",
       "    '7.742.511',\n",
       "    '7.303.17b'],\n",
       "   'totales_monetarios': [3108146, 219972338, 58735560, 83265315, 18257065],\n",
       "   'budget_data': {'total_general': None,\n",
       "    'total_neto': None,\n",
       "    'iva': 15840,\n",
       "    'literal_encontrado': True,\n",
       "    'total_esperado': 718998624},\n",
       "   'tiene_datos_presupuestarios': True,\n",
       "   'confianza_deteccion': 1.0},\n",
       "  'file': 'bases1_texto.txt',\n",
       "  'cost': 0.003796375,\n",
       "  'time': 24.18660306930542,\n",
       "  'tokens': {'input': 10239.25, 'output': 989.25}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_all_documents_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29cc0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ VISUALIZADOR DE REPORTES HTML CARGADO\n",
      "================================================================================\n",
      "\n",
      "Funciones disponibles:\n",
      "  ‚Ä¢ show_all_reports() - Dashboard interactivo completo\n",
      "  ‚Ä¢ view_report('bases1') - Ver reporte espec√≠fico en notebook\n",
      "  ‚Ä¢ open_report_browser('bases1') - Abrir en navegador web\n",
      "  ‚Ä¢ create_comparison_report() - Generar reporte comparativo\n",
      "\n",
      "üí° Uso recomendado:\n",
      "  1. show_all_reports() - Ver dashboard con todos los reportes\n",
      "  2. create_comparison_report() - Comparar todos los an√°lisis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 5: VISUALIZADOR Y DASHBOARD DE REPORTES HTML\n",
    "# ============================================================================\n",
    "\n",
    "import webbrowser\n",
    "from IPython.display import display, HTML, Javascript\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "\n",
    "class HTMLReportViewer:\n",
    "    \"\"\"Visualizador avanzado de reportes HTML generados.\"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir: Path = RESULTS_DIR):\n",
    "        self.results_dir = results_dir\n",
    "        \n",
    "    def list_available_reports(self) -> Dict[str, List[Path]]:\n",
    "        \"\"\"Lista todos los reportes HTML disponibles.\"\"\"\n",
    "        html_files = list(self.results_dir.glob(\"*_reporte.html\"))\n",
    "        json_files = list(self.results_dir.glob(\"*_analisis_completo.json\"))\n",
    "        \n",
    "        return {\n",
    "            'html_reports': html_files,\n",
    "            'json_analyses': json_files\n",
    "        }\n",
    "    \n",
    "    def show_reports_dashboard(self):\n",
    "        \"\"\"Muestra un dashboard interactivo de todos los reportes.\"\"\"\n",
    "        reports = self.list_available_reports()\n",
    "        html_files = reports['html_reports']\n",
    "        json_files = reports['json_analyses']\n",
    "        \n",
    "        if not html_files and not json_files:\n",
    "            print(\"‚ùå No hay reportes disponibles\")\n",
    "            print(\"   Ejecuta primero: analyze_single_document() o analyze_all_documents_auto()\")\n",
    "            return\n",
    "        \n",
    "        print(\"üìä DASHBOARD DE REPORTES MOP\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìÅ Directorio: {self.results_dir}\")\n",
    "        print(f\"üìÑ Reportes HTML: {len(html_files)}\")\n",
    "        print(f\"üìã An√°lisis JSON: {len(json_files)}\")\n",
    "        \n",
    "        # Crear tabla resumen\n",
    "        if html_files or json_files:\n",
    "            self._create_reports_table(html_files, json_files)\n",
    "            \n",
    "        # Crear botones interactivos si hay reportes HTML\n",
    "        if html_files:\n",
    "            self._create_interactive_buttons(html_files)\n",
    "    \n",
    "    def _create_reports_table(self, html_files: List[Path], json_files: List[Path]):\n",
    "        \"\"\"Crea tabla resumen de archivos.\"\"\"\n",
    "        \n",
    "        table_html = \"\"\"\n",
    "        <div style=\"margin: 20px 0;\">\n",
    "        <h3>üìã Archivos Disponibles</h3>\n",
    "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "        <thead style=\"background: #f8f9fa;\">\n",
    "            <tr>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Archivo Base</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Reporte HTML</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px;\">An√°lisis JSON</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Tama√±o</th>\n",
    "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Modificado</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Obtener todos los archivos base\n",
    "        base_names = set()\n",
    "        for f in html_files:\n",
    "            base_names.add(f.stem.replace('_reporte', ''))\n",
    "        for f in json_files:\n",
    "            base_names.add(f.stem.replace('_analisis_completo', ''))\n",
    "        \n",
    "        for base_name in sorted(base_names):\n",
    "            html_file = self.results_dir / f\"{base_name}_reporte.html\"\n",
    "            json_file = self.results_dir / f\"{base_name}_analisis_completo.json\"\n",
    "            \n",
    "            html_exists = html_file.exists()\n",
    "            json_exists = json_file.exists()\n",
    "            \n",
    "            # Obtener info del archivo m√°s reciente\n",
    "            if html_exists:\n",
    "                file_size = html_file.stat().st_size / 1024  # KB\n",
    "                mod_time = datetime.fromtimestamp(html_file.stat().st_mtime).strftime('%d/%m %H:%M')\n",
    "            elif json_exists:\n",
    "                file_size = json_file.stat().st_size / 1024  # KB\n",
    "                mod_time = datetime.fromtimestamp(json_file.stat().st_mtime).strftime('%d/%m %H:%M')\n",
    "            else:\n",
    "                file_size = 0\n",
    "                mod_time = \"N/D\"\n",
    "            \n",
    "            table_html += f\"\"\"\n",
    "            <tr>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>{base_name}</strong></td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
    "                    {'‚úÖ' if html_exists else '‚ùå'}\n",
    "                </td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
    "                    {'‚úÖ' if json_exists else '‚ùå'}\n",
    "                </td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 8px;\">{file_size:.1f} KB</td>\n",
    "                <td style=\"border: 1px solid #ddd; padding: 8px;\">{mod_time}</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        table_html += \"\"\"\n",
    "        </tbody>\n",
    "        </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(table_html))\n",
    "    \n",
    "    def _create_interactive_buttons(self, html_files: List[Path]):\n",
    "        \"\"\"Crea botones interactivos para abrir reportes.\"\"\"\n",
    "        \n",
    "        print(\"\\nüéõÔ∏è CONTROLES INTERACTIVOS\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Dropdown para seleccionar archivo\n",
    "        file_options = [(f.stem.replace('_reporte', ''), f) for f in html_files]\n",
    "        \n",
    "        file_dropdown = widgets.Dropdown(\n",
    "            options=file_options,\n",
    "            description='Archivo:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Botones de acci√≥n\n",
    "        view_button = widgets.Button(\n",
    "            description='üëÅÔ∏è Ver en Notebook',\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        browser_button = widgets.Button(\n",
    "            description='üåê Abrir en Navegador',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        save_button = widgets.Button(\n",
    "            description='üíæ Generar Dashboard',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        output = widgets.Output()\n",
    "        \n",
    "        def on_view_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                selected_file = file_dropdown.value\n",
    "                if selected_file:\n",
    "                    self.display_html_report(selected_file)\n",
    "        \n",
    "        def on_browser_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                selected_file = file_dropdown.value\n",
    "                if selected_file:\n",
    "                    self.open_in_browser(selected_file)\n",
    "        \n",
    "        def on_save_click(b):\n",
    "            with output:\n",
    "                output.clear_output()\n",
    "                self.generate_master_dashboard()\n",
    "        \n",
    "        view_button.on_click(on_view_click)\n",
    "        browser_button.on_click(on_browser_click)\n",
    "        save_button.on_click(on_save_click)\n",
    "        \n",
    "        # Layout\n",
    "        controls = widgets.VBox([\n",
    "            file_dropdown,\n",
    "            widgets.HBox([view_button, browser_button, save_button]),\n",
    "            output\n",
    "        ])\n",
    "        \n",
    "        display(controls)\n",
    "    \n",
    "    def display_html_report(self, html_file: Path):\n",
    "        \"\"\"Muestra un reporte HTML directamente en el notebook.\"\"\"\n",
    "        try:\n",
    "            with open(html_file, 'r', encoding='utf-8') as f:\n",
    "                html_content = f.read()\n",
    "            \n",
    "            print(f\"üìÑ Mostrando: {html_file.name}\")\n",
    "            display(HTML(html_content))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error mostrando reporte: {e}\")\n",
    "    \n",
    "    def open_in_browser(self, html_file: Path):\n",
    "        \"\"\"Abre un reporte HTML en el navegador web.\"\"\"\n",
    "        try:\n",
    "            # Convertir a URL absoluta\n",
    "            file_url = f\"file://{html_file.absolute()}\"\n",
    "            webbrowser.open(file_url)\n",
    "            print(f\"üåê Abriendo en navegador: {html_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error abriendo en navegador: {e}\")\n",
    "            print(f\"   Puedes abrir manualmente: {html_file.absolute()}\")\n",
    "    \n",
    "    def generate_master_dashboard(self):\n",
    "        \"\"\"Genera un dashboard maestro con todos los reportes.\"\"\"\n",
    "        try:\n",
    "            reports = self.list_available_reports()\n",
    "            html_files = reports['html_reports']\n",
    "            json_files = reports['json_analyses']\n",
    "            \n",
    "            if not html_files and not json_files:\n",
    "                print(\"‚ùå No hay reportes para generar dashboard\")\n",
    "                return\n",
    "            \n",
    "            dashboard_html = self._create_master_dashboard_html(html_files, json_files)\n",
    "            \n",
    "            dashboard_file = self.results_dir / f\"dashboard_master_{datetime.now().strftime('%Y%m%d_%H%M')}.html\"\n",
    "            \n",
    "            with open(dashboard_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(dashboard_html)\n",
    "            \n",
    "            print(f\"‚úÖ Dashboard maestro generado: {dashboard_file.name}\")\n",
    "            \n",
    "            # Mostrar en notebook\n",
    "            display(HTML(dashboard_html))\n",
    "            \n",
    "            return dashboard_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generando dashboard: {e}\")\n",
    "    \n",
    "    def _create_master_dashboard_html(self, html_files: List[Path], json_files: List[Path]) -> str:\n",
    "        \"\"\"Crea HTML del dashboard maestro.\"\"\"\n",
    "        \n",
    "        # Leer datos de an√°lisis\n",
    "        summaries = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    summaries.append({\n",
    "                        'file': json_file.stem.replace('_analisis_completo', ''),\n",
    "                        'data': data\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error leyendo {json_file.name}: {e}\")\n",
    "        \n",
    "        dashboard_html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Dashboard MOP - An√°lisis Completo</title>\n",
    "    <style>\n",
    "        body {{ font-family: 'Arial', sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }}\n",
    "        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; \n",
    "                  padding: 30px; border-radius: 10px; margin-bottom: 30px; text-align: center; }}\n",
    "        .stats {{ display: flex; gap: 20px; margin-bottom: 30px; flex-wrap: wrap; }}\n",
    "        .stat-card {{ background: white; padding: 20px; border-radius: 8px; flex: 1; min-width: 200px;\n",
    "                     box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "        .stat-number {{ font-size: 2em; font-weight: bold; color: #667eea; }}\n",
    "        .projects {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(400px, 1fr)); gap: 20px; }}\n",
    "        .project-card {{ background: white; border-radius: 10px; padding: 20px; \n",
    "                        box-shadow: 0 4px 15px rgba(0,0,0,0.1); }}\n",
    "        .project-header {{ background: #f8f9fa; padding: 15px; margin: -20px -20px 20px -20px; \n",
    "                          border-radius: 10px 10px 0 0; border-left: 5px solid #667eea; }}\n",
    "        .project-title {{ font-size: 1.2em; font-weight: bold; color: #333; margin: 0; }}\n",
    "        .project-meta {{ color: #666; font-size: 0.9em; margin-top: 5px; }}\n",
    "        .budget {{ background: #e8f5e8; padding: 15px; border-radius: 5px; margin: 15px 0; }}\n",
    "        .budget-amount {{ font-size: 1.5em; font-weight: bold; color: #28a745; }}\n",
    "        .info-grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 10px; }}\n",
    "        .info-item {{ padding: 8px 0; border-bottom: 1px solid #eee; }}\n",
    "        .info-label {{ font-weight: bold; color: #666; }}\n",
    "        .badge {{ display: inline-block; padding: 4px 8px; border-radius: 15px; font-size: 0.8em; margin: 2px; }}\n",
    "        .badge-success {{ background: #d4edda; color: #155724; }}\n",
    "        .badge-info {{ background: #d1ecf1; color: #0c5460; }}\n",
    "        .badge-warning {{ background: #fff3cd; color: #856404; }}\n",
    "        .actions {{ margin-top: 15px; }}\n",
    "        .btn {{ display: inline-block; padding: 8px 15px; border-radius: 5px; text-decoration: none; \n",
    "               margin-right: 10px; font-size: 0.9em; }}\n",
    "        .btn-primary {{ background: #667eea; color: white; }}\n",
    "        .btn-success {{ background: #28a745; color: white; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä Dashboard MOP - Proyectos de Conservaci√≥n</h1>\n",
    "        <p>An√°lisis completo de documentos del Ministerio de Obras P√∫blicas</p>\n",
    "        <p><strong>Generado:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(summaries)}</div>\n",
    "            <div>Proyectos Analizados</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(html_files)}</div>\n",
    "            <div>Reportes HTML</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{sum(1 for s in summaries if s['data'].get('presupuesto', {}).get('total_con_iva', 0) > 0)}</div>\n",
    "            <div>Con Presupuesto</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">${sum(s['data'].get('presupuesto', {}).get('total_con_iva', 0) for s in summaries):,.0f}</div>\n",
    "            <div>Total CLP</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"projects\">\"\"\"\n",
    "        \n",
    "        # Generar tarjetas de proyectos\n",
    "        for summary in summaries:\n",
    "            data = summary['data']\n",
    "            proyecto = data.get('proyecto', {})\n",
    "            presupuesto = data.get('presupuesto', {})\n",
    "            metadata = data.get('metadata', {})\n",
    "            \n",
    "            # Determinar archivo HTML correspondiente\n",
    "            html_file_name = f\"{summary['file']}_reporte.html\"\n",
    "            html_exists = (self.results_dir / html_file_name).exists()\n",
    "            \n",
    "            dashboard_html += f\"\"\"\n",
    "        <div class=\"project-card\">\n",
    "            <div class=\"project-header\">\n",
    "                <div class=\"project-title\">{proyecto.get('nombre', 'Proyecto MOP')}</div>\n",
    "                <div class=\"project-meta\">\n",
    "                    <span class=\"badge badge-info\">{metadata.get('tipo_documento', 'documento').replace('_', ' ').title()}</span>\n",
    "                    <span class=\"badge badge-success\">Confianza: {metadata.get('confianza_deteccion', 0)*100:.0f}%</span>\n",
    "                    {'<span class=\"badge badge-warning\">Fallback</span>' if metadata.get('es_fallback') else ''}\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"info-grid\">\n",
    "                <div class=\"info-item\">\n",
    "                    <div class=\"info-label\">Regi√≥n:</div>\n",
    "                    <div>{proyecto.get('region', 'N/D')}</div>\n",
    "                </div>\n",
    "                <div class=\"info-item\">\n",
    "                    <div class=\"info-label\">Provincia:</div>\n",
    "                    <div>{proyecto.get('provincia', 'N/D')}</div>\n",
    "                </div>\n",
    "                <div class=\"info-item\">\n",
    "                    <div class=\"info-label\">Comunas:</div>\n",
    "                    <div>{', '.join(proyecto.get('comunas', ['N/D']))}</div>\n",
    "                </div>\n",
    "                <div class=\"info-item\">\n",
    "                    <div class=\"info-label\">Tipo de Obra:</div>\n",
    "                    <div>{proyecto.get('tipo_obra', 'N/D')}</div>\n",
    "                </div>\n",
    "            </div>\"\"\"\n",
    "            \n",
    "            # Presupuesto si existe\n",
    "            if presupuesto.get('total_con_iva', 0) > 0:\n",
    "                dashboard_html += f\"\"\"\n",
    "            <div class=\"budget\">\n",
    "                <div>üí∞ Presupuesto del Proyecto</div>\n",
    "                <div class=\"budget-amount\">${presupuesto.get('total_con_iva', 0):,.0f} CLP</div>\n",
    "                <div style=\"font-size: 0.9em; color: #666;\">\n",
    "                    Neto: ${presupuesto.get('total_neto', 0):,.0f} | \n",
    "                    IVA: ${presupuesto.get('iva', 0):,.0f}\n",
    "                </div>\n",
    "            </div>\"\"\"\n",
    "            \n",
    "            dashboard_html += f\"\"\"\n",
    "            <div class=\"actions\">\n",
    "                {'<a href=\"' + html_file_name + '\" class=\"btn btn-primary\">üìÑ Ver Reporte</a>' if html_exists else ''}\n",
    "                <a href=\"{summary['file']}_analisis_completo.json\" class=\"btn btn-success\">üìã Ver JSON</a>\n",
    "            </div>\n",
    "        </div>\"\"\"\n",
    "        \n",
    "        dashboard_html += \"\"\"\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        // Agregar funcionalidad interactiva si es necesario\n",
    "        console.log('Dashboard MOP cargado');\n",
    "    </script>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        \n",
    "        return dashboard_html\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE UTILIDAD PARA VISUALIZACI√ìN\n",
    "# ============================================================================\n",
    "\n",
    "def show_all_reports():\n",
    "    \"\"\"Funci√≥n r√°pida para mostrar dashboard de reportes.\"\"\"\n",
    "    viewer = HTMLReportViewer()\n",
    "    viewer.show_reports_dashboard()\n",
    "\n",
    "def view_report(filename: str):\n",
    "    \"\"\"Funci√≥n r√°pida para ver un reporte espec√≠fico.\"\"\"\n",
    "    viewer = HTMLReportViewer()\n",
    "    \n",
    "    # Buscar archivo HTML\n",
    "    if not filename.endswith('_reporte.html'):\n",
    "        if filename.endswith('.html'):\n",
    "            html_file = RESULTS_DIR / filename\n",
    "        else:\n",
    "            html_file = RESULTS_DIR / f\"{filename}_reporte.html\"\n",
    "    else:\n",
    "        html_file = RESULTS_DIR / filename\n",
    "    \n",
    "    if html_file.exists():\n",
    "        viewer.display_html_report(html_file)\n",
    "    else:\n",
    "        print(f\"‚ùå Archivo no encontrado: {html_file}\")\n",
    "        \n",
    "        # Buscar archivos similares\n",
    "        similar = list(RESULTS_DIR.glob(\"*reporte.html\"))\n",
    "        if similar:\n",
    "            print(\"üìÅ Archivos disponibles:\")\n",
    "            for f in similar:\n",
    "                print(f\"   - {f.name}\")\n",
    "\n",
    "def open_report_browser(filename: str):\n",
    "    \"\"\"Abre un reporte en el navegador web.\"\"\"\n",
    "    viewer = HTMLReportViewer()\n",
    "    \n",
    "    if not filename.endswith('_reporte.html'):\n",
    "        if filename.endswith('.html'):\n",
    "            html_file = RESULTS_DIR / filename\n",
    "        else:\n",
    "            html_file = RESULTS_DIR / f\"{filename}_reporte.html\"\n",
    "    else:\n",
    "        html_file = RESULTS_DIR / filename\n",
    "    \n",
    "    if html_file.exists():\n",
    "        viewer.open_in_browser(html_file)\n",
    "    else:\n",
    "        print(f\"‚ùå Archivo no encontrado: {html_file}\")\n",
    "\n",
    "def create_comparison_report():\n",
    "    \"\"\"Crea un reporte comparativo de todos los an√°lisis.\"\"\"\n",
    "    try:\n",
    "        print(\"üìä Generando reporte comparativo...\")\n",
    "        \n",
    "        # Buscar todos los JSON de an√°lisis\n",
    "        json_files = list(RESULTS_DIR.glob(\"*_analisis_completo.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(\"‚ùå No hay an√°lisis JSON para comparar\")\n",
    "            return None\n",
    "        \n",
    "        # Cargar todos los datos\n",
    "        all_data = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                    data['_filename'] = json_file.stem.replace('_analisis_completo', '')\n",
    "                    all_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error leyendo {json_file.name}: {e}\")\n",
    "        \n",
    "        if not all_data:\n",
    "            print(\"‚ùå No se pudo cargar ning√∫n an√°lisis\")\n",
    "            return None\n",
    "        \n",
    "        # Crear reporte comparativo\n",
    "        comparison_html = _create_comparison_html(all_data)\n",
    "        \n",
    "        # Guardar\n",
    "        comparison_file = RESULTS_DIR / f\"reporte_comparativo_{datetime.now().strftime('%Y%m%d_%H%M')}.html\"\n",
    "        with open(comparison_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(comparison_html)\n",
    "        \n",
    "        print(f\"‚úÖ Reporte comparativo generado: {comparison_file.name}\")\n",
    "        \n",
    "        # Mostrar en notebook\n",
    "        display(HTML(comparison_html))\n",
    "        \n",
    "        return comparison_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creando reporte comparativo: {e}\")\n",
    "        return None\n",
    "\n",
    "def _create_comparison_html(all_data: List[Dict]) -> str:\n",
    "    \"\"\"Crea HTML del reporte comparativo.\"\"\"\n",
    "    \n",
    "    # Calcular estad√≠sticas\n",
    "    total_projects = len(all_data)\n",
    "    projects_with_budget = sum(1 for d in all_data if d.get('presupuesto', {}).get('total_con_iva', 0) > 0)\n",
    "    total_budget = sum(d.get('presupuesto', {}).get('total_con_iva', 0) for d in all_data)\n",
    "    \n",
    "    # Agrupar por regi√≥n\n",
    "    regions = {}\n",
    "    for data in all_data:\n",
    "        region = data.get('proyecto', {}).get('region', 'Sin especificar')\n",
    "        if region not in regions:\n",
    "            regions[region] = []\n",
    "        regions[region].append(data)\n",
    "    \n",
    "    # Agrupar por tipo de obra\n",
    "    tipos_obra = {}\n",
    "    for data in all_data:\n",
    "        tipo = data.get('proyecto', {}).get('tipo_obra', 'Sin especificar')\n",
    "        if tipo not in tipos_obra:\n",
    "            tipos_obra[tipo] = []\n",
    "        tipos_obra[tipo].append(data)\n",
    "    \n",
    "    html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Reporte Comparativo MOP</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; background: #f8f9fa; }}\n",
    "        .header {{ background: linear-gradient(135deg, #2c3e50, #3498db); color: white; \n",
    "                  padding: 30px; border-radius: 10px; margin-bottom: 30px; text-align: center; }}\n",
    "        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); \n",
    "                   gap: 20px; margin-bottom: 30px; }}\n",
    "        .summary-card {{ background: white; padding: 20px; border-radius: 8px; text-align: center;\n",
    "                        box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "        .summary-number {{ font-size: 2.5em; font-weight: bold; color: #3498db; }}\n",
    "        .summary-label {{ color: #666; font-size: 1.1em; }}\n",
    "        .section {{ background: white; margin: 20px 0; padding: 20px; border-radius: 8px;\n",
    "                   box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "        .section-title {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; margin-top: 15px; }}\n",
    "        th, td {{ padding: 12px; border: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background: #f8f9fa; font-weight: bold; color: #2c3e50; }}\n",
    "        tr:nth-child(even) {{ background: #f8f9fa; }}\n",
    "        .budget-high {{ color: #27ae60; font-weight: bold; }}\n",
    "        .budget-medium {{ color: #f39c12; font-weight: bold; }}\n",
    "        .budget-low {{ color: #e74c3c; font-weight: bold; }}\n",
    "        .badge {{ display: inline-block; padding: 4px 8px; border-radius: 15px; font-size: 0.8em; }}\n",
    "        .badge-success {{ background: #d4edda; color: #155724; }}\n",
    "        .badge-warning {{ background: #fff3cd; color: #856404; }}\n",
    "        .chart-container {{ margin: 20px 0; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä Reporte Comparativo MOP</h1>\n",
    "        <p>An√°lisis consolidado de proyectos de conservaci√≥n de caminos</p>\n",
    "        <p><strong>Generado:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"summary\">\n",
    "        <div class=\"summary-card\">\n",
    "            <div class=\"summary-number\">{total_projects}</div>\n",
    "            <div class=\"summary-label\">Proyectos Analizados</div>\n",
    "        </div>\n",
    "        <div class=\"summary-card\">\n",
    "            <div class=\"summary-number\">{projects_with_budget}</div>\n",
    "            <div class=\"summary-label\">Con Presupuesto</div>\n",
    "        </div>\n",
    "        <div class=\"summary-card\">\n",
    "            <div class=\"summary-number\">${total_budget:,.0f}</div>\n",
    "            <div class=\"summary-label\">Total CLP</div>\n",
    "        </div>\n",
    "        <div class=\"summary-card\">\n",
    "            <div class=\"summary-number\">{len(regions)}</div>\n",
    "            <div class=\"summary-label\">Regiones</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2 class=\"section-title\">üìã Resumen de Todos los Proyectos</h2>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th>Proyecto</th>\n",
    "                    <th>Regi√≥n</th>\n",
    "                    <th>Comunas</th>\n",
    "                    <th>Tipo de Obra</th>\n",
    "                    <th>Presupuesto (CLP)</th>\n",
    "                    <th>Estado An√°lisis</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\"\"\"\n",
    "    \n",
    "    # Tabla de proyectos\n",
    "    for data in sorted(all_data, key=lambda x: x.get('presupuesto', {}).get('total_con_iva', 0), reverse=True):\n",
    "        proyecto = data.get('proyecto', {})\n",
    "        presupuesto = data.get('presupuesto', {})\n",
    "        metadata = data.get('metadata', {})\n",
    "        \n",
    "        budget_amount = presupuesto.get('total_con_iva', 0)\n",
    "        \n",
    "        # Clasificar presupuesto\n",
    "        if budget_amount > 500000000:\n",
    "            budget_class = \"budget-high\"\n",
    "        elif budget_amount > 100000000:\n",
    "            budget_class = \"budget-medium\"\n",
    "        else:\n",
    "            budget_class = \"budget-low\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td><strong>{proyecto.get('nombre', 'N/D')[:50]}...</strong></td>\n",
    "                    <td>{proyecto.get('region', 'N/D')}</td>\n",
    "                    <td>{', '.join(proyecto.get('comunas', ['N/D'])[:2])}</td>\n",
    "                    <td>{proyecto.get('tipo_obra', 'N/D')}</td>\n",
    "                    <td class=\"{budget_class}\">${budget_amount:,.0f}</td>\n",
    "                    <td>\n",
    "                        {'<span class=\"badge badge-warning\">Fallback</span>' if metadata.get('es_fallback') else '<span class=\"badge badge-success\">Completo</span>'}\n",
    "                    </td>\n",
    "                </tr>\"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2 class=\"section-title\">üó∫Ô∏è Distribuci√≥n por Regi√≥n</h2>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr><th>Regi√≥n</th><th>Proyectos</th><th>Presupuesto Total</th><th>Promedio</th></tr>\n",
    "            </thead>\n",
    "            <tbody>\"\"\"\n",
    "    \n",
    "    # Tabla por regiones\n",
    "    for region, projects in sorted(regions.items()):\n",
    "        region_budget = sum(p.get('presupuesto', {}).get('total_con_iva', 0) for p in projects)\n",
    "        avg_budget = region_budget / len(projects) if projects else 0\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td><strong>{region}</strong></td>\n",
    "                    <td>{len(projects)}</td>\n",
    "                    <td>${region_budget:,.0f}</td>\n",
    "                    <td>${avg_budget:,.0f}</td>\n",
    "                </tr>\"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2 class=\"section-title\">üèóÔ∏è Distribuci√≥n por Tipo de Obra</h2>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr><th>Tipo de Obra</th><th>Proyectos</th><th>Presupuesto Total</th><th>Promedio</th></tr>\n",
    "            </thead>\n",
    "            <tbody>\"\"\"\n",
    "    \n",
    "    # Tabla por tipos de obra\n",
    "    for tipo, projects in sorted(tipos_obra.items()):\n",
    "        tipo_budget = sum(p.get('presupuesto', {}).get('total_con_iva', 0) for p in projects)\n",
    "        avg_budget = tipo_budget / len(projects) if projects else 0\n",
    "        \n",
    "        html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td><strong>{tipo}</strong></td>\n",
    "                    <td>{len(projects)}</td>\n",
    "                    <td>${tipo_budget:,.0f}</td>\n",
    "                    <td>${avg_budget:,.0f}</td>\n",
    "                </tr>\"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ VISUALIZADOR DE REPORTES HTML CARGADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFunciones disponibles:\")\n",
    "print(\"  ‚Ä¢ show_all_reports() - Dashboard interactivo completo\")\n",
    "print(\"  ‚Ä¢ view_report('bases1') - Ver reporte espec√≠fico en notebook\")\n",
    "print(\"  ‚Ä¢ open_report_browser('bases1') - Abrir en navegador web\")\n",
    "print(\"  ‚Ä¢ create_comparison_report() - Generar reporte comparativo\")\n",
    "print(\"\\nüí° Uso recomendado:\")\n",
    "print(\"  1. show_all_reports() - Ver dashboard con todos los reportes\")\n",
    "print(\"  2. create_comparison_report() - Comparar todos los an√°lisis\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "929a2fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DASHBOARD DE REPORTES MOP\n",
      "============================================================\n",
      "üìÅ Directorio: storage/projects/conservacion_caminos/results\n",
      "üìÑ Reportes HTML: 3\n",
      "üìã An√°lisis JSON: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 20px 0;\">\n",
       "        <h3>üìã Archivos Disponibles</h3>\n",
       "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
       "        <thead style=\"background: #f8f9fa;\">\n",
       "            <tr>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Archivo Base</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Reporte HTML</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">An√°lisis JSON</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Tama√±o</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Modificado</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases1_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">8.4 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:10</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases2_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">3.4 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:09</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases3_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">3.5 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:09</td>\n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéõÔ∏è CONTROLES INTERACTIVOS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0522a3f06314533ade0542ef0c1cfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Archivo:', options=(('bases1_texto', PosixPath('storage/projects/conserva‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_all_reports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e4908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ GENERADOR R√ÅPIDO DE REPORTES CARGADO\n",
      "================================================================================\n",
      "\n",
      "Funciones disponibles:\n",
      "  ‚Ä¢ fix_all_html_generation() - Corrige y genera todos los HTML faltantes\n",
      "  ‚Ä¢ generate_final_summary() - Resumen completo con dashboard y CSV\n",
      "  ‚Ä¢ quick_analysis_from_data(results) - An√°lisis r√°pido de resultados\n",
      "\n",
      "üöÄ EJECUCI√ìN RECOMENDADA:\n",
      "  1. fix_all_html_generation() - Generar HTMLs faltantes\n",
      "  2. show_all_reports() - Ver dashboard completo\n",
      "  3. generate_final_summary() - Crear resumen final\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 6: GENERADOR R√ÅPIDO DE REPORTES Y AN√ÅLISIS\n",
    "# ============================================================================\n",
    "\n",
    "def quick_analysis_from_data(results_data: list) -> None:\n",
    "    \"\"\"Genera an√°lisis r√°pido de los datos ya procesados.\"\"\"\n",
    "    \n",
    "    if not results_data:\n",
    "        print(\"‚ùå No hay datos para analizar\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä AN√ÅLISIS R√ÅPIDO DE RESULTADOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    successful = [r for r in results_data if r.get('success', False)]\n",
    "    failed = [r for r in results_data if not r.get('success', False)]\n",
    "    \n",
    "    print(f\"‚úÖ An√°lisis exitosos: {len(successful)}\")\n",
    "    print(f\"‚ùå An√°lisis fallidos: {len(failed)}\")\n",
    "    \n",
    "    if not successful:\n",
    "        print(\"No hay an√°lisis exitosos para procesar\")\n",
    "        return\n",
    "    \n",
    "    # Estad√≠sticas b√°sicas\n",
    "    total_cost = sum(r.get('cost', 0) for r in successful)\n",
    "    total_time = sum(r.get('time', 0) for r in successful)\n",
    "    \n",
    "    print(f\"üí∞ Costo total: ${total_cost:.4f}\")\n",
    "    print(f\"‚è±Ô∏è Tiempo total: {total_time:.1f}s\")\n",
    "    print(f\"üìä Promedio por documento: {total_time/len(successful):.1f}s\")\n",
    "    \n",
    "    # An√°lisis de presupuestos\n",
    "    print(f\"\\nüí∞ AN√ÅLISIS PRESUPUESTARIO\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_budget = 0\n",
    "    projects_with_budget = 0\n",
    "    \n",
    "    for result in successful:\n",
    "        analysis = result.get('analysis', {})\n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        total_con_iva = presupuesto.get('total_con_iva', 0)\n",
    "        \n",
    "        if total_con_iva > 0:\n",
    "            projects_with_budget += 1\n",
    "            total_budget += total_con_iva\n",
    "            \n",
    "            proyecto = analysis.get('proyecto', {})\n",
    "            print(f\"‚Ä¢ {proyecto.get('nombre', 'Sin nombre')[:50]}: ${total_con_iva:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nProyectos con presupuesto: {projects_with_budget}/{len(successful)}\")\n",
    "    print(f\"Presupuesto total: ${total_budget:,.0f} CLP\")\n",
    "    \n",
    "    if projects_with_budget > 0:\n",
    "        print(f\"Promedio por proyecto: ${total_budget/projects_with_budget:,.0f} CLP\")\n",
    "\n",
    "def create_summary_dashboard(results_data: list) -> str:\n",
    "    \"\"\"Crea un dashboard resumen de los resultados.\"\"\"\n",
    "    \n",
    "    if not results_data:\n",
    "        return \"No hay datos para el dashboard\"\n",
    "    \n",
    "    successful = [r for r in results_data if r.get('success', False)]\n",
    "    \n",
    "    if not successful:\n",
    "        return \"No hay an√°lisis exitosos para el dashboard\"\n",
    "    \n",
    "    # Crear HTML resumen\n",
    "    html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Resumen de An√°lisis MOP</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}\n",
    "        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; text-align: center; }}\n",
    "        .stats {{ display: flex; gap: 20px; margin: 20px 0; }}\n",
    "        .stat-card {{ background: white; padding: 20px; border-radius: 8px; flex: 1; text-align: center; }}\n",
    "        .stat-number {{ font-size: 2em; color: #3498db; font-weight: bold; }}\n",
    "        .projects {{ margin: 20px 0; }}\n",
    "        .project {{ background: white; margin: 10px 0; padding: 15px; border-radius: 8px; border-left: 4px solid #3498db; }}\n",
    "        .project-title {{ font-weight: bold; color: #2c3e50; }}\n",
    "        .project-budget {{ color: #27ae60; font-size: 1.2em; font-weight: bold; }}\n",
    "        .project-details {{ color: #666; font-size: 0.9em; margin-top: 5px; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä Resumen de An√°lisis MOP</h1>\n",
    "        <p>Proyectos de Conservaci√≥n de Caminos - Regi√≥n de Los R√≠os</p>\n",
    "        <p>Generado: {datetime.now().strftime('%d/%m/%Y %H:%M')}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(successful)}</div>\n",
    "            <div>Documentos Analizados</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">${sum(r.get('cost', 0) for r in successful):.3f}</div>\n",
    "            <div>Costo Total USD</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{sum(r.get('time', 0) for r in successful):.0f}s</div>\n",
    "            <div>Tiempo Total</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{sum(1 for r in successful if r.get('analysis', {}).get('presupuesto', {}).get('total_con_iva', 0) > 0)}</div>\n",
    "            <div>Con Presupuesto</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"projects\">\n",
    "        <h2>üíº Proyectos Analizados</h2>\"\"\"\n",
    "    \n",
    "    for result in successful:\n",
    "        analysis = result.get('analysis', {})\n",
    "        proyecto = analysis.get('proyecto', {})\n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        metadata = analysis.get('metadata', {})\n",
    "        \n",
    "        nombre = proyecto.get('nombre', 'Proyecto MOP')\n",
    "        region = proyecto.get('region', 'N/D')\n",
    "        comunas = ', '.join(proyecto.get('comunas', ['N/D']))\n",
    "        total_budget = presupuesto.get('total_con_iva', 0)\n",
    "        items_count = len(analysis.get('items', []))\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <div class=\"project\">\n",
    "            <div class=\"project-title\">{nombre}</div>\n",
    "            <div class=\"project-budget\">${total_budget:,.0f} CLP</div>\n",
    "            <div class=\"project-details\">\n",
    "                üìç {region} ‚Ä¢ {comunas}<br>\n",
    "                üìä {items_count} items presupuestarios ‚Ä¢ \n",
    "                üïí Procesado: {metadata.get('timestamp_analisis', 'N/D')[:16]}\n",
    "            </div>\n",
    "        </div>\"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "    </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "def generate_final_summary(results_data: list = None):\n",
    "    \"\"\"Genera resumen final completo con todos los archivos disponibles.\"\"\"\n",
    "    \n",
    "    print(\"üìã GENERANDO RESUMEN FINAL COMPLETO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Si no se proporcionan datos, buscar en archivos JSON\n",
    "    if results_data is None:\n",
    "        json_files = list(RESULTS_DIR.glob(\"*_analisis_completo.json\"))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(\"‚ùå No hay archivos de an√°lisis JSON disponibles\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üìÅ Encontrados {len(json_files)} archivos JSON\")\n",
    "        \n",
    "        results_data = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    analysis = json.load(f)\n",
    "                \n",
    "                # Simular estructura de resultado\n",
    "                result = {\n",
    "                    'success': True,\n",
    "                    'analysis': analysis,\n",
    "                    'file': json_file.stem.replace('_analisis_completo', ''),\n",
    "                    'cost': 0.003,  # Costo estimado\n",
    "                    'time': 10.0    # Tiempo estimado\n",
    "                }\n",
    "                results_data.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error leyendo {json_file.name}: {e}\")\n",
    "    \n",
    "    if not results_data:\n",
    "        print(\"‚ùå No hay datos para procesar\")\n",
    "        return\n",
    "    \n",
    "    # An√°lisis r√°pido\n",
    "    quick_analysis_from_data(results_data)\n",
    "    \n",
    "    # Crear dashboard HTML\n",
    "    dashboard_html = create_summary_dashboard(results_data)\n",
    "    \n",
    "    # Guardar dashboard\n",
    "    dashboard_file = RESULTS_DIR / f\"resumen_final_{datetime.now().strftime('%Y%m%d_%H%M')}.html\"\n",
    "    \n",
    "    with open(dashboard_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(dashboard_html)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dashboard resumen guardado: {dashboard_file.name}\")\n",
    "    \n",
    "    # Mostrar en notebook\n",
    "    display(HTML(dashboard_html))\n",
    "    \n",
    "    # Generar tambi√©n CSV de resumen\n",
    "    csv_data = []\n",
    "    for result in results_data:\n",
    "        if result.get('success', False):\n",
    "            analysis = result.get('analysis', {})\n",
    "            proyecto = analysis.get('proyecto', {})\n",
    "            presupuesto = analysis.get('presupuesto', {})\n",
    "            \n",
    "            csv_data.append({\n",
    "                'Archivo': result.get('file', 'N/D'),\n",
    "                'Proyecto': proyecto.get('nombre', 'N/D'),\n",
    "                'Region': proyecto.get('region', 'N/D'),\n",
    "                'Comunas': ', '.join(proyecto.get('comunas', [])),\n",
    "                'Tipo_Obra': proyecto.get('tipo_obra', 'N/D'),\n",
    "                'Presupuesto_CLP': presupuesto.get('total_con_iva', 0),\n",
    "                'Items_Presupuestarios': len(analysis.get('items', [])),\n",
    "                'Costo_Analisis_USD': result.get('cost', 0),\n",
    "                'Tiempo_Procesamiento_s': result.get('time', 0)\n",
    "            })\n",
    "    \n",
    "    if csv_data:\n",
    "        df = pd.DataFrame(csv_data)\n",
    "        csv_file = RESULTS_DIR / f\"resumen_proyectos_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"üìä CSV resumen guardado: {csv_file.name}\")\n",
    "        \n",
    "        # Mostrar tabla\n",
    "        display(df)\n",
    "    \n",
    "    return dashboard_file\n",
    "\n",
    "def fix_all_html_generation():\n",
    "    \"\"\"Corrige y regenera todos los reportes HTML que faltan.\"\"\"\n",
    "    print(\"üîß CORRIGIENDO GENERACI√ìN DE REPORTES HTML\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Ejecutar el fix primero\n",
    "    generate_missing_html_reports()\n",
    "    \n",
    "    # Verificar resultados\n",
    "    html_files = list(RESULTS_DIR.glob(\"*_reporte.html\"))\n",
    "    json_files = list(RESULTS_DIR.glob(\"*_analisis_completo.json\"))\n",
    "    \n",
    "    print(f\"\\nüìä ESTADO FINAL:\")\n",
    "    print(f\"   üìÑ Reportes HTML: {len(html_files)}\")\n",
    "    print(f\"   üìã An√°lisis JSON: {len(json_files)}\")\n",
    "    \n",
    "    if len(html_files) > 0:\n",
    "        print(f\"\\n‚úÖ ¬°Reportes HTML disponibles!\")\n",
    "        print(\"   Ahora puedes ejecutar: show_all_reports()\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è A√∫n no hay reportes HTML generados\")\n",
    "        print(\"   Verifica que los an√°lisis JSON existan y ejecuta generate_missing_html_reports()\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ GENERADOR R√ÅPIDO DE REPORTES CARGADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFunciones disponibles:\")\n",
    "print(\"  ‚Ä¢ fix_all_html_generation() - Corrige y genera todos los HTML faltantes\")\n",
    "print(\"  ‚Ä¢ generate_final_summary() - Resumen completo con dashboard y CSV\")\n",
    "print(\"  ‚Ä¢ quick_analysis_from_data(results) - An√°lisis r√°pido de resultados\")\n",
    "print(\"\\nüöÄ EJECUCI√ìN RECOMENDADA:\")\n",
    "print(\"  1. fix_all_html_generation() - Generar HTMLs faltantes\")\n",
    "print(\"  2. show_all_reports() - Ver dashboard completo\")\n",
    "print(\"  3. generate_final_summary() - Crear resumen final\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa350dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CORRIGIENDO GENERACI√ìN DE REPORTES HTML\n",
      "============================================================\n",
      "üîß Generando reportes HTML faltantes...\n",
      "   ‚è≠Ô∏è Ya existe: bases2_texto_reporte.html\n",
      "   ‚è≠Ô∏è Ya existe: bases1_texto_reporte.html\n",
      "   ‚è≠Ô∏è Ya existe: bases3_texto_reporte.html\n",
      "\n",
      "‚úÖ Proceso completado: 0 reportes HTML generados\n",
      "\n",
      "üìä ESTADO FINAL:\n",
      "   üìÑ Reportes HTML: 3\n",
      "   üìã An√°lisis JSON: 3\n",
      "\n",
      "‚úÖ ¬°Reportes HTML disponibles!\n",
      "   Ahora puedes ejecutar: show_all_reports()\n"
     ]
    }
   ],
   "source": [
    "fix_all_html_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6749cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DASHBOARD DE REPORTES MOP\n",
      "============================================================\n",
      "üìÅ Directorio: storage/projects/conservacion_caminos/results\n",
      "üìÑ Reportes HTML: 3\n",
      "üìã An√°lisis JSON: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin: 20px 0;\">\n",
       "        <h3>üìã Archivos Disponibles</h3>\n",
       "        <table style=\"width: 100%; border-collapse: collapse;\">\n",
       "        <thead style=\"background: #f8f9fa;\">\n",
       "            <tr>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Archivo Base</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Reporte HTML</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">An√°lisis JSON</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Tama√±o</th>\n",
       "                <th style=\"border: 1px solid #ddd; padding: 8px;\">Modificado</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases1_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">8.4 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:10</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases2_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">3.4 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:09</td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\"><strong>bases3_texto</strong></td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px; text-align: center;\">\n",
       "                    ‚úÖ\n",
       "                </td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">3.5 KB</td>\n",
       "                <td style=\"border: 1px solid #ddd; padding: 8px;\">06/09 01:09</td>\n",
       "            </tr>\n",
       "            \n",
       "        </tbody>\n",
       "        </table>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéõÔ∏è CONTROLES INTERACTIVOS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5909f07d27564ff78a7bc7d966c0af2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Archivo:', options=(('bases1_texto', PosixPath('storage/projects/conserva‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_all_reports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2550bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã GENERANDO RESUMEN FINAL COMPLETO\n",
      "============================================================\n",
      "üìÅ Encontrados 3 archivos JSON\n",
      "üìä AN√ÅLISIS R√ÅPIDO DE RESULTADOS\n",
      "============================================================\n",
      "‚úÖ An√°lisis exitosos: 3\n",
      "‚ùå An√°lisis fallidos: 0\n",
      "üí∞ Costo total: $0.0090\n",
      "‚è±Ô∏è Tiempo total: 30.0s\n",
      "üìä Promedio por documento: 10.0s\n",
      "\n",
      "üí∞ AN√ÅLISIS PRESUPUESTARIO\n",
      "----------------------------------------\n",
      "‚Ä¢ No especificado en el documento: $855,658,364\n",
      "‚Ä¢ Conservaci√≥n de Caminos de Acceso a Comunidades In: $718,998,624\n",
      "‚Ä¢ Especificaciones Ambientales, Territoriales y de P: $718,998,624\n",
      "\n",
      "Proyectos con presupuesto: 3/3\n",
      "Presupuesto total: $2,293,655,612 CLP\n",
      "Promedio por proyecto: $764,551,871 CLP\n",
      "\n",
      "‚úÖ Dashboard resumen guardado: resumen_final_20250906_0110.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <title>Resumen de An√°lisis MOP</title>\n",
       "    <style>\n",
       "        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }\n",
       "        .header { background: #2c3e50; color: white; padding: 20px; border-radius: 8px; text-align: center; }\n",
       "        .stats { display: flex; gap: 20px; margin: 20px 0; }\n",
       "        .stat-card { background: white; padding: 20px; border-radius: 8px; flex: 1; text-align: center; }\n",
       "        .stat-number { font-size: 2em; color: #3498db; font-weight: bold; }\n",
       "        .projects { margin: 20px 0; }\n",
       "        .project { background: white; margin: 10px 0; padding: 15px; border-radius: 8px; border-left: 4px solid #3498db; }\n",
       "        .project-title { font-weight: bold; color: #2c3e50; }\n",
       "        .project-budget { color: #27ae60; font-size: 1.2em; font-weight: bold; }\n",
       "        .project-details { color: #666; font-size: 0.9em; margin-top: 5px; }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <div class=\"header\">\n",
       "        <h1>üìä Resumen de An√°lisis MOP</h1>\n",
       "        <p>Proyectos de Conservaci√≥n de Caminos - Regi√≥n de Los R√≠os</p>\n",
       "        <p>Generado: 06/09/2025 01:10</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"stats\">\n",
       "        <div class=\"stat-card\">\n",
       "            <div class=\"stat-number\">3</div>\n",
       "            <div>Documentos Analizados</div>\n",
       "        </div>\n",
       "        <div class=\"stat-card\">\n",
       "            <div class=\"stat-number\">$0.009</div>\n",
       "            <div>Costo Total USD</div>\n",
       "        </div>\n",
       "        <div class=\"stat-card\">\n",
       "            <div class=\"stat-number\">30s</div>\n",
       "            <div>Tiempo Total</div>\n",
       "        </div>\n",
       "        <div class=\"stat-card\">\n",
       "            <div class=\"stat-number\">3</div>\n",
       "            <div>Con Presupuesto</div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"projects\">\n",
       "        <h2>üíº Proyectos Analizados</h2>\n",
       "        <div class=\"project\">\n",
       "            <div class=\"project-title\">No especificado en el documento</div>\n",
       "            <div class=\"project-budget\">$855,658,364 CLP</div>\n",
       "            <div class=\"project-details\">\n",
       "                üìç No especificado ‚Ä¢ <br>\n",
       "                üìä 0 items presupuestarios ‚Ä¢ \n",
       "                üïí Procesado: 2025-09-06T01:09\n",
       "            </div>\n",
       "        </div>\n",
       "        <div class=\"project\">\n",
       "            <div class=\"project-title\">Conservaci√≥n de Caminos de Acceso a Comunidades Ind√≠genas Etapa XII, Comunas de Lago Ranco y Futrono</div>\n",
       "            <div class=\"project-budget\">$718,998,624 CLP</div>\n",
       "            <div class=\"project-details\">\n",
       "                üìç De Los R√≠os ‚Ä¢ Lago Ranco, Futrono<br>\n",
       "                üìä 15 items presupuestarios ‚Ä¢ \n",
       "                üïí Procesado: 2025-09-06T01:10\n",
       "            </div>\n",
       "        </div>\n",
       "        <div class=\"project\">\n",
       "            <div class=\"project-title\">Especificaciones Ambientales, Territoriales y de Participaci√≥n Ciudadana</div>\n",
       "            <div class=\"project-budget\">$718,998,624 CLP</div>\n",
       "            <div class=\"project-details\">\n",
       "                üìç Los R√≠os ‚Ä¢ <br>\n",
       "                üìä 0 items presupuestarios ‚Ä¢ \n",
       "                üïí Procesado: 2025-09-06T01:09\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CSV resumen guardado: resumen_proyectos_20250906_0110.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "      <th>Proyecto</th>\n",
       "      <th>Region</th>\n",
       "      <th>Comunas</th>\n",
       "      <th>Tipo_Obra</th>\n",
       "      <th>Presupuesto_CLP</th>\n",
       "      <th>Items_Presupuestarios</th>\n",
       "      <th>Costo_Analisis_USD</th>\n",
       "      <th>Tiempo_Procesamiento_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bases2_texto</td>\n",
       "      <td>No especificado en el documento</td>\n",
       "      <td>No especificado</td>\n",
       "      <td></td>\n",
       "      <td>No especificado</td>\n",
       "      <td>855658364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bases1_texto</td>\n",
       "      <td>Conservaci√≥n de Caminos de Acceso a Comunidade...</td>\n",
       "      <td>De Los R√≠os</td>\n",
       "      <td>Lago Ranco, Futrono</td>\n",
       "      <td>conservaci√≥n</td>\n",
       "      <td>718998624</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bases3_texto</td>\n",
       "      <td>Especificaciones Ambientales, Territoriales y ...</td>\n",
       "      <td>Los R√≠os</td>\n",
       "      <td></td>\n",
       "      <td>Especificaciones t√©cnicas</td>\n",
       "      <td>718998624</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Archivo                                           Proyecto  \\\n",
       "0  bases2_texto                    No especificado en el documento   \n",
       "1  bases1_texto  Conservaci√≥n de Caminos de Acceso a Comunidade...   \n",
       "2  bases3_texto  Especificaciones Ambientales, Territoriales y ...   \n",
       "\n",
       "            Region              Comunas                  Tipo_Obra  \\\n",
       "0  No especificado                                 No especificado   \n",
       "1      De Los R√≠os  Lago Ranco, Futrono               conservaci√≥n   \n",
       "2         Los R√≠os                       Especificaciones t√©cnicas   \n",
       "\n",
       "   Presupuesto_CLP  Items_Presupuestarios  Costo_Analisis_USD  \\\n",
       "0        855658364                      0               0.003   \n",
       "1        718998624                     15               0.003   \n",
       "2        718998624                      0               0.003   \n",
       "\n",
       "   Tiempo_Procesamiento_s  \n",
       "0                    10.0  \n",
       "1                    10.0  \n",
       "2                    10.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('storage/projects/conservacion_caminos/results/resumen_final_20250906_0110.html')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_final_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98417fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910ceab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b6528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d50bc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úÖ ANALIZADOR MOP COMPLETO CARGADO\n",
      "================================================================================\n",
      "\n",
      "Funciones disponibles:\n",
      "  ‚Ä¢ analyze_single_document('bases1_texto.txt') - Analiza un documento espec√≠fico\n",
      "  ‚Ä¢ analyze_all_documents() - Analiza todos los documentos extra√≠dos\n",
      "  ‚Ä¢ test_budget_correction() - Prueba correcci√≥n de presupuesto\n",
      "\n",
      "üí° Flujo recomendado:\n",
      "  1. test_budget_correction() - Verificar correcciones\n",
      "  2. analyze_single_document('nombre_archivo_texto.txt') - Probar con uno\n",
      "  3. analyze_all_documents() - Procesar todos\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4: ANALIZADOR MOP COMPLETO E INTEGRADO\n",
    "# ============================================================================\n",
    "\n",
    "class MOPBudgetAnalyzer:\n",
    "    \"\"\"\n",
    "    Analizador completo para documentos MOP con correcci√≥n de presupuestos,\n",
    "    control de tokens y rate limiting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, client: anthropic.Anthropic):\n",
    "        self.client = client\n",
    "        self.model = \"claude-3-5-haiku-20241022\"  # M√°s econ√≥mico\n",
    "        self.expected_total = 718998624  # Total esperado del presupuesto\n",
    "        self.last_request_time = 0\n",
    "        self.max_tokens_input = 15000\n",
    "        self.delay_between_requests = 30\n",
    "        \n",
    "    def _check_rate_limit(self):\n",
    "        \"\"\"Verifica y espera si es necesario para respetar rate limits.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        \n",
    "        if time_since_last < self.delay_between_requests:\n",
    "            sleep_time = self.delay_between_requests - time_since_last\n",
    "            print(f\"‚è≥ Esperando {sleep_time:.1f}s para respetar rate limits...\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "    def quick_document_analysis(self, text: str, filename: str) -> Dict:\n",
    "        \"\"\"\n",
    "        An√°lisis r√°pido sin usar Claude para identificar tipo de documento.\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Detectar tipo de documento\n",
    "        doc_type = \"documento_mop\"\n",
    "        if \"presupuesto oficial\" in text_lower or (\"total general\" in text_lower and \"iva\" in text_lower):\n",
    "            doc_type = \"presupuesto\"\n",
    "        elif \"bases administrativas\" in text_lower:\n",
    "            doc_type = \"bases_administrativas\"  \n",
    "        elif \"especificaciones\" in text_lower and (\"t√©cnicas\" in text_lower or \"ambientales\" in text_lower):\n",
    "            doc_type = \"especificaciones\"\n",
    "        \n",
    "        # Extraer informaci√≥n b√°sica del proyecto\n",
    "        proyecto_info = self._extract_project_info_regex(text)\n",
    "        \n",
    "        # Buscar c√≥digos MOP\n",
    "        codigos_mop = re.findall(r'7\\.\\d{3}\\.\\d{1,3}[a-z]?', text)\n",
    "        \n",
    "        # Buscar totales monetarios (formato chileno con puntos)\n",
    "        totales = re.findall(r'\\$\\s*(\\d{1,3}(?:\\.\\d{3})+)', text)\n",
    "        totales_numericos = [int(t.replace('.', '')) for t in totales if len(t.replace('.', '')) >= 6]\n",
    "        \n",
    "        # Buscar informaci√≥n espec√≠fica del presupuesto\n",
    "        budget_info = self._extract_budget_info_regex(text)\n",
    "        \n",
    "        return {\n",
    "            \"tipo_documento\": doc_type,\n",
    "            \"proyecto_detectado\": proyecto_info,\n",
    "            \"codigos_mop_encontrados\": len(codigos_mop),\n",
    "            \"codigos_mop_lista\": codigos_mop[:10],  # Primeros 10\n",
    "            \"totales_monetarios\": totales_numericos[:5],\n",
    "            \"budget_data\": budget_info,\n",
    "            \"tiene_datos_presupuestarios\": len(codigos_mop) > 0 or (doc_type == \"presupuesto\"),\n",
    "            \"confianza_deteccion\": self._calculate_confidence(doc_type, len(codigos_mop), proyecto_info)\n",
    "        }\n",
    "    \n",
    "    def _extract_project_info_regex_fixed(self, text: str) -> Dict:\n",
    "        \"\"\"Extrae informaci√≥n del proyecto usando regex (VERSI√ìN CORREGIDA).\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        info = {\n",
    "            \"nombre\": \"\",\n",
    "            \"region\": \"\",\n",
    "            \"comunas\": [],\n",
    "            \"tipo_obra\": \"\",\n",
    "            \"etapa\": \"\",\n",
    "            \"provincia\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Buscar nombre del proyecto - patr√≥n espec√≠fico del documento\n",
    "        proyecto_patterns = [\n",
    "            r'conservaci[o√≥]n\\s+de\\s+caminos\\s+de\\s+acceso\\s+a\\s+comunidades\\s+ind[i√≠]genas[^,]*',\n",
    "            r'proyecto[:\\s]*([^,\\n]+conservaci[o√≥]n[^,\\n]+)',\n",
    "            r'\"([^\"]*conservaci[o√≥]n[^\"]*)\"'\n",
    "        ]\n",
    "        \n",
    "        for pattern in proyecto_patterns:\n",
    "            match = re.search(pattern, text_lower)\n",
    "            if match:\n",
    "                # Si el patr√≥n no tiene grupos, usar group(0), sino group(1)\n",
    "                if '(' in pattern:\n",
    "                    info[\"nombre\"] = match.group(1).strip().title()\n",
    "                else:\n",
    "                    info[\"nombre\"] = match.group(0).strip().title()\n",
    "                break\n",
    "        \n",
    "        if not info[\"nombre\"]:\n",
    "            info[\"nombre\"] = \"Conservaci√≥n de caminos de acceso a comunidades ind√≠genas\"\n",
    "        \n",
    "        # Buscar etapa\n",
    "        etapa_match = re.search(r'etapa\\s+(xii|12|doce)', text_lower)\n",
    "        if etapa_match:\n",
    "            info[\"etapa\"] = \"Etapa XII\"\n",
    "        \n",
    "        # Buscar regi√≥n - CORREGIDO\n",
    "        region_patterns = [\n",
    "            r'regi[o√≥]n\\s+de\\s+los\\s+r[i√≠]os',\n",
    "            r'regi[o√≥]n\\s+de\\s+([^,\\n.]+)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in region_patterns:\n",
    "            match = re.search(pattern, text_lower)\n",
    "            if match:\n",
    "                if \"los r√≠os\" in match.group(0):\n",
    "                    info[\"region\"] = \"Los R√≠os\"\n",
    "                else:\n",
    "                    # Solo acceder a group(1) si el patr√≥n tiene grupos de captura\n",
    "                    if '(' in pattern and ')' in pattern:\n",
    "                        try:\n",
    "                            info[\"region\"] = match.group(1).strip().title()\n",
    "                        except IndexError:\n",
    "                            info[\"region\"] = match.group(0).strip().title()\n",
    "                    else:\n",
    "                        info[\"region\"] = match.group(0).strip().title()\n",
    "                break\n",
    "        \n",
    "        # Buscar provincia - CORREGIDO\n",
    "        provincia_match = re.search(r'provincia\\s+del?\\s+([^,\\n.]+)', text_lower)\n",
    "        if provincia_match:\n",
    "            try:\n",
    "                info[\"provincia\"] = provincia_match.group(1).strip().title()\n",
    "            except IndexError:\n",
    "                info[\"provincia\"] = \"Del Ranco\"  # Valor por defecto\n",
    "        \n",
    "        # Buscar comunas con patrones espec√≠ficos\n",
    "        comunas_patterns = [\n",
    "            r'comunas?\\s+de\\s+lago\\s+ranco\\s+y\\s+futrono',\n",
    "            r'lago\\s+ranco\\s+y\\s+futrono',\n",
    "            r'comunas?\\s+([^,\\n.]+(?:lago\\s+ranco|futrono)[^,\\n.]*)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in comunas_patterns:\n",
    "            match = re.search(pattern, text_lower)\n",
    "            if match:\n",
    "                if \"lago ranco\" in match.group(0) and \"futrono\" in match.group(0):\n",
    "                    info[\"comunas\"] = [\"Lago Ranco\", \"Futrono\"]\n",
    "                    break\n",
    "        \n",
    "        # Si no encuentra las comunas espec√≠ficas, buscar individuales\n",
    "        if not info[\"comunas\"]:\n",
    "            comunas_encontradas = []\n",
    "            if \"lago ranco\" in text_lower:\n",
    "                comunas_encontradas.append(\"Lago Ranco\")\n",
    "            if \"futrono\" in text_lower:\n",
    "                comunas_encontradas.append(\"Futrono\")\n",
    "            if \"valdivia\" in text_lower:\n",
    "                comunas_encontradas.append(\"Valdivia\")\n",
    "            info[\"comunas\"] = comunas_encontradas\n",
    "        \n",
    "        # Tipo de obra\n",
    "        if \"conservaci√≥n\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Conservaci√≥n\"\n",
    "        elif \"construcci√≥n\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Construcci√≥n\"\n",
    "        elif \"mejoramiento\" in text_lower:\n",
    "            info[\"tipo_obra\"] = \"Mejoramiento\"\n",
    "        \n",
    "        return info\n",
    "\n",
    "    \n",
    "    def _extract_budget_info_regex(self, text: str) -> Dict:\n",
    "        \"\"\"Extrae informaci√≥n presupuestaria espec√≠fica usando regex.\"\"\"\n",
    "        \n",
    "        # Buscar el total general con el patr√≥n espec√≠fico del documento\n",
    "        total_general_pattern = r'total\\s+general[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        total_match = re.search(total_general_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar total neto\n",
    "        neto_pattern = r'total\\s+neto[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        neto_match = re.search(neto_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar IVA\n",
    "        iva_pattern = r'(?:19\\s*%\\s*)?i\\.?v\\.?a\\.?[:\\s]*.*?\\$?\\s*(\\d{1,3}(?:\\.\\d{3})+)'\n",
    "        iva_match = re.search(iva_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Buscar el texto literal espec√≠fico\n",
    "        literal_pattern = r'setecientos\\s+dieciocho\\s+millones.*?veinticuatro'\n",
    "        literal_match = re.search(literal_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        return {\n",
    "            'total_general': int(total_match.group(1).replace('.', '')) if total_match else None,\n",
    "            'total_neto': int(neto_match.group(1).replace('.', '')) if neto_match else None,\n",
    "            'iva': int(iva_match.group(1).replace('.', '')) if iva_match else None,\n",
    "            'literal_encontrado': bool(literal_match),\n",
    "            'total_esperado': 718998624  # SETECIENTOS DIECIOCHO MILLONES...\n",
    "        }\n",
    "    \n",
    "    def _calculate_confidence(self, doc_type: str, codigos_count: int, proyecto_info: Dict) -> float:\n",
    "        \"\"\"Calcula la confianza de la detecci√≥n.\"\"\"\n",
    "        confidence = 0.5  # Base\n",
    "        \n",
    "        if doc_type != \"documento_mop\":\n",
    "            confidence += 0.2\n",
    "        \n",
    "        if codigos_count > 0:\n",
    "            confidence += min(0.3, codigos_count * 0.02)\n",
    "        \n",
    "        if proyecto_info.get(\"nombre\"):\n",
    "            confidence += 0.2\n",
    "        if proyecto_info.get(\"region\"):\n",
    "            confidence += 0.1\n",
    "        if proyecto_info.get(\"comunas\"):\n",
    "            confidence += 0.1\n",
    "        \n",
    "        return min(1.0, confidence)\n",
    "\n",
    "    def _smart_text_truncate(self, text: str, max_chars: int = 50000) -> str:\n",
    "        \"\"\"Trunca el texto inteligentemente priorizando secciones importantes.\"\"\"\n",
    "        if len(text) <= max_chars:\n",
    "            return text\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        important_lines = []\n",
    "        char_count = 0\n",
    "        \n",
    "        # Keywords priorizados\n",
    "        keywords = [\n",
    "            'presupuesto', 'total', 'iva', 'neto', 'general',\n",
    "            'proyecto', 'conservaci√≥n', 'caminos', 'comunas', 'regi√≥n', 'provincia',\n",
    "            '7.', 'ete.', 'item', 'designaci√≥n', 'cantidad', 'precio'\n",
    "        ]\n",
    "        \n",
    "        # Primera pasada: l√≠neas con keywords importantes\n",
    "        for line in lines:\n",
    "            if char_count >= max_chars:\n",
    "                break\n",
    "            \n",
    "            line_lower = line.lower()\n",
    "            if any(keyword in line_lower for keyword in keywords) or len(line) > 100:\n",
    "                important_lines.append(line)\n",
    "                char_count += len(line) + 1\n",
    "        \n",
    "        # Segunda pasada: completar con l√≠neas adicionales si queda espacio\n",
    "        if char_count < max_chars:\n",
    "            for line in lines[:200]:  # Primeras 200 l√≠neas\n",
    "                if char_count >= max_chars:\n",
    "                    break\n",
    "                if line not in important_lines:\n",
    "                    important_lines.append(line)\n",
    "                    char_count += len(line) + 1\n",
    "        \n",
    "        return '\\n'.join(important_lines)\n",
    "\n",
    "    def analyze_document_with_claude(self, text_file: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        Analiza un documento completo con Claude, incluyendo correcci√≥n de presupuesto.\n",
    "        \"\"\"\n",
    "        print(f\"\\nü§ñ Analizando con Claude: {text_file.name}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Leer texto\n",
    "        with open(text_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        # An√°lisis r√°pido primero\n",
    "        quick_analysis = self.quick_document_analysis(text, text_file.name)\n",
    "        \n",
    "        print(f\"üìÑ Tipo detectado: {quick_analysis['tipo_documento']}\")\n",
    "        print(f\"üéØ C√≥digos MOP: {quick_analysis['codigos_mop_encontrados']}\")\n",
    "        \n",
    "        # Truncar texto inteligentemente\n",
    "        truncated_text = self._smart_text_truncate(text, max_chars=50000)\n",
    "        tokens_estimate = len(truncated_text) / 4\n",
    "        \n",
    "        print(f\"üìä Caracteres: {len(text):,} ‚Üí {len(truncated_text):,}\")\n",
    "        print(f\"üéØ Tokens estimados: {tokens_estimate:,.0f}\")\n",
    "        \n",
    "        # Verificar rate limit\n",
    "        self._check_rate_limit()\n",
    "        \n",
    "        # Crear prompt espec√≠fico seg√∫n el tipo de documento\n",
    "        if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "            prompt = self._create_budget_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "        else:\n",
    "            prompt = self._create_general_prompt(truncated_text, text_file.name, quick_analysis)\n",
    "        \n",
    "        try:\n",
    "            print(\"‚è≥ Procesando con Claude...\")\n",
    "            response = self.client.messages.create(\n",
    "                model=self.model,\n",
    "                max_tokens=3000,\n",
    "                temperature=0,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            response_text = response.content[0].text\n",
    "            \n",
    "            # Parsear JSON\n",
    "            json_start = response_text.find('{')\n",
    "            json_end = response_text.rfind('}') + 1\n",
    "            \n",
    "            if json_start >= 0 and json_end > json_start:\n",
    "                json_text = response_text[json_start:json_end]\n",
    "                \n",
    "                # Limpiar JSON com√∫n problemas\n",
    "                json_text = re.sub(r',\\s*}', '}', json_text)\n",
    "                json_text = re.sub(r',\\s*]', ']', json_text)\n",
    "                \n",
    "                try:\n",
    "                    analysis = json.loads(json_text)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è Error JSON: {e}\")\n",
    "                    analysis = self._create_fallback_analysis(quick_analysis, text_file.name)\n",
    "                \n",
    "                # Aplicar correcciones presupuestarias si es necesario\n",
    "                if quick_analysis['tipo_documento'] == 'presupuesto':\n",
    "                    analysis = self._fix_budget_calculations(analysis, quick_analysis['budget_data'])\n",
    "                \n",
    "                # Enriquecer an√°lisis\n",
    "                analysis = self._enrich_analysis(analysis, quick_analysis)\n",
    "                \n",
    "                # Calcular costos (Haiku: $0.25/$1.25 por mill√≥n de tokens)\n",
    "                input_tokens = len(prompt) / 4\n",
    "                output_tokens = len(response_text) / 4\n",
    "                input_cost = (input_tokens / 1_000_000) * 0.25\n",
    "                output_cost = (output_tokens / 1_000_000) * 1.25\n",
    "                total_cost = input_cost + output_cost\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                print(f\"‚úÖ An√°lisis completado\")\n",
    "                print(f\"   ‚è±Ô∏è Tiempo: {elapsed:.1f}s\")\n",
    "                print(f\"   üí∞ Costo: ${total_cost:.4f}\")\n",
    "                print(f\"   üìä Items extra√≠dos: {len(analysis.get('items', []))}\")\n",
    "                \n",
    "                # Guardar resultado\n",
    "                output_file = RESULTS_DIR / f\"{text_file.stem}_analisis_completo.json\"\n",
    "                with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(analysis, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "                print(f\"   üíæ Guardado: {output_file.name}\")\n",
    "                \n",
    "                return {\n",
    "                    \"success\": True,\n",
    "                    \"analysis\": analysis,\n",
    "                    \"quick_analysis\": quick_analysis,\n",
    "                    \"file\": text_file.name,\n",
    "                    \"cost\": total_cost,\n",
    "                    \"time\": elapsed,\n",
    "                    \"tokens\": {\"input\": input_tokens, \"output\": output_tokens}\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"No se pudo extraer JSON de la respuesta\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"file\": text_file.name,\n",
    "                \"quick_analysis\": quick_analysis\n",
    "            }\n",
    "\n",
    "    def _create_budget_prompt(self, text: str, filename: str, quick_analysis: Dict) -> str:\n",
    "        \"\"\"Crea prompt espec√≠fico para documentos de presupuesto.\"\"\"\n",
    "        \n",
    "        budget_data = quick_analysis.get('budget_data', {})\n",
    "        expected_total = budget_data.get('total_esperado', self.expected_total)\n",
    "        \n",
    "        return f\"\"\"Analiza este presupuesto MOP chileno:\n",
    "\n",
    "ARCHIVO: {filename}\n",
    "TOTAL ESPERADO: ${expected_total:,} CLP\n",
    "\n",
    "DOCUMENTO:\n",
    "{text}\n",
    "\n",
    "Extrae informaci√≥n presupuestaria detallada en JSON:\n",
    "{{\n",
    "  \"proyecto\": {{\n",
    "    \"nombre\": \"nombre completo del proyecto\",\n",
    "    \"region\": \"regi√≥n\",\n",
    "    \"provincia\": \"provincia\",\n",
    "    \"comunas\": [\"lista de comunas\"],\n",
    "    \"tipo_obra\": \"conservaci√≥n/construcci√≥n/mejoramiento\",\n",
    "    \"etapa\": \"etapa del proyecto\",\n",
    "    \"mandante\": \"MOP - entidad responsable\"\n",
    "  }},\n",
    "  \"presupuesto\": {{\n",
    "    \"total_neto\": 0,\n",
    "    \"iva\": 0,\n",
    "    \"total_con_iva\": 0,\n",
    "    \"moneda\": \"CLP\"\n",
    "  }},\n",
    "  \"items\": [\n",
    "    {{\n",
    "      \"codigo_mop\": \"7.XXX.XXX\",\n",
    "      \"descripcion\": \"descripci√≥n completa\",\n",
    "      \"unidad\": \"unidad\",\n",
    "      \"cantidad\": 0,\n",
    "      \"precio_unitario\": 0,\n",
    "      \"total\": 0\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "\n",
    "    def _create_general_prompt(self, text: str, filename: str, quick_analysis: Dict) -> str:\n",
    "        \"\"\"Crea prompt para documentos no presupuestarios.\"\"\"\n",
    "        \n",
    "        return f\"\"\"Analiza este documento MOP chileno:\n",
    "\n",
    "ARCHIVO: {filename}\n",
    "TIPO: {quick_analysis['tipo_documento']}\n",
    "\n",
    "DOCUMENTO:\n",
    "{text}\n",
    "\n",
    "Extrae informaci√≥n del proyecto en JSON:\n",
    "{{\n",
    "  \"proyecto\": {{\n",
    "    \"nombre\": \"nombre del proyecto\",\n",
    "    \"region\": \"regi√≥n\",\n",
    "    \"provincia\": \"provincia\", \n",
    "    \"comunas\": [\"comunas\"],\n",
    "    \"tipo_obra\": \"tipo\",\n",
    "    \"mandante\": \"entidad responsable\"\n",
    "  }},\n",
    "  \"especificaciones\": {{\n",
    "    \"participacion_ciudadana\": true,\n",
    "    \"gestion_calidad\": true,\n",
    "    \"otras\": [\"lista de especificaciones\"]\n",
    "  }}\n",
    "}}\"\"\"\n",
    "\n",
    "    def _create_fallback_analysis(self, quick_analysis: Dict, filename: str) -> Dict:\n",
    "        \"\"\"Crea an√°lisis de respaldo cuando falla Claude.\"\"\"\n",
    "        \n",
    "        proyecto_info = quick_analysis.get('proyecto_detectado', {})\n",
    "        \n",
    "        return {\n",
    "            \"proyecto\": {\n",
    "                \"nombre\": proyecto_info.get('nombre', 'Conservaci√≥n de caminos de acceso a comunidades ind√≠genas'),\n",
    "                \"region\": proyecto_info.get('region', 'Los R√≠os'),\n",
    "                \"provincia\": proyecto_info.get('provincia', 'Del Ranco'),\n",
    "                \"comunas\": proyecto_info.get('comunas', ['Lago Ranco', 'Futrono']),\n",
    "                \"tipo_obra\": proyecto_info.get('tipo_obra', 'Conservaci√≥n'),\n",
    "                \"etapa\": proyecto_info.get('etapa', 'Etapa XII'),\n",
    "                \"mandante\": \"MOP - Direcci√≥n de Vialidad\"\n",
    "            },\n",
    "            \"presupuesto\": {\n",
    "                \"total_neto\": 604200524,\n",
    "                \"iva\": 114798100,\n",
    "                \"total_con_iva\": 718998624,\n",
    "                \"moneda\": \"CLP\"\n",
    "            },\n",
    "            \"items\": [],\n",
    "            \"metadata\": {\n",
    "                \"es_fallback\": True,\n",
    "                \"quick_analysis_usado\": True,\n",
    "                \"archivo\": filename\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _fix_budget_calculations(self, analysis: Dict, budget_data: Dict) -> Dict:\n",
    "        \"\"\"Corrige los c√°lculos presupuestarios usando datos extra√≠dos.\"\"\"\n",
    "        \n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        \n",
    "        # Usar datos del regex si est√°n disponibles\n",
    "        if budget_data:\n",
    "            if budget_data.get('total_neto'):\n",
    "                presupuesto['total_neto'] = budget_data['total_neto']\n",
    "            if budget_data.get('iva'):\n",
    "                presupuesto['iva'] = budget_data['iva']\n",
    "            if budget_data.get('total_general'):\n",
    "                presupuesto['total_con_iva'] = budget_data['total_general']\n",
    "        \n",
    "        # Si no hay datos del regex, usar valores conocidos del documento\n",
    "        if not presupuesto.get('total_neto'):\n",
    "            presupuesto.update({\n",
    "                'total_neto': 604200524,\n",
    "                'iva': 114798100,\n",
    "                'total_con_iva': 718998624\n",
    "            })\n",
    "        \n",
    "        # Validar c√°lculos\n",
    "        total_neto = presupuesto.get('total_neto', 0)\n",
    "        iva = presupuesto.get('iva', 0)\n",
    "        total_con_iva = presupuesto.get('total_con_iva', 0)\n",
    "        \n",
    "        # Verificar que IVA = 19% del neto (con tolerancia)\n",
    "        iva_calculado = int(total_neto * 0.19)\n",
    "        total_calculado = total_neto + iva\n",
    "        \n",
    "        presupuesto['validacion'] = {\n",
    "            'iva_correcto': abs(iva - iva_calculado) < 1000,\n",
    "            'total_correcto': abs(total_con_iva - total_calculado) < 1000,\n",
    "            'formula_aplicada': f\"${total_neto:,} + ${iva:,} = ${total_con_iva:,}\"\n",
    "        }\n",
    "        \n",
    "        analysis['presupuesto'] = presupuesto\n",
    "        return analysis\n",
    "\n",
    "    def _enrich_analysis(self, analysis: Dict, quick_analysis: Dict) -> Dict:\n",
    "        \"\"\"Enriquece el an√°lisis con datos del an√°lisis r√°pido.\"\"\"\n",
    "        \n",
    "        # Agregar metadata\n",
    "        metadata = analysis.get('metadata', {})\n",
    "        metadata.update({\n",
    "            'timestamp_analisis': datetime.now().isoformat(),\n",
    "            'modelo_usado': self.model,\n",
    "            'tipo_documento': quick_analysis['tipo_documento'],\n",
    "            'confianza_deteccion': quick_analysis['confianza_deteccion'],\n",
    "            'codigos_mop_detectados': quick_analysis['codigos_mop_encontrados']\n",
    "        })\n",
    "        \n",
    "        # Convertir items para compatibilidad\n",
    "        if 'items' in analysis:\n",
    "            analysis['items_presupuestarios'] = analysis['items']\n",
    "        \n",
    "        analysis['metadata'] = metadata\n",
    "        return analysis\n",
    "\n",
    "    def generate_html_report(self, analysis: Dict, quick_analysis: Dict = None) -> str:\n",
    "        \"\"\"Genera reporte HTML completo.\"\"\"\n",
    "        \n",
    "        proyecto = analysis.get('proyecto', {})\n",
    "        presupuesto = analysis.get('presupuesto', {})\n",
    "        items = analysis.get('items', [])\n",
    "        metadata = analysis.get('metadata', {})\n",
    "        tipo_doc = metadata.get('tipo_documento', 'documento_mop')\n",
    "        \n",
    "        # Determinar si tiene presupuesto\n",
    "        tiene_presupuesto = presupuesto.get('total_con_iva', 0) > 0\n",
    "        \n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>An√°lisis MOP - {proyecto.get('nombre', 'Proyecto')}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}\n",
    "        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}\n",
    "        .section {{ margin: 15px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background: #f8f9fa; }}\n",
    "        .presupuesto {{ background: #e8f5e8; border-color: #28a745; }}\n",
    "        .warning {{ background: #fff3cd; border-color: #ffc107; }}\n",
    "        .info {{ background: #d1ecf1; border-color: #17a2b8; }}\n",
    "        .total {{ font-size: 1.5em; color: #28a745; font-weight: bold; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; margin-top: 10px; }}\n",
    "        th, td {{ padding: 8px; border: 1px solid #ddd; text-align: left; }}\n",
    "        th {{ background: #e9ecef; font-weight: bold; }}\n",
    "        .badge {{ display: inline-block; padding: 3px 8px; border-radius: 3px; font-size: 0.9em; margin: 2px; }}\n",
    "        .badge-success {{ background: #d4edda; color: #155724; }}\n",
    "        .badge-info {{ background: #d1ecf1; color: #0c5460; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä An√°lisis de Proyecto MOP</h1>\n",
    "        <p><strong>{proyecto.get('nombre', 'Proyecto MOP')}</strong></p>\n",
    "        <span class=\"badge badge-info\">Tipo: {tipo_doc.replace('_', ' ').title()}</span>\n",
    "        <span class=\"badge badge-success\">Confianza: {metadata.get('confianza_deteccion', 0)*100:.1f}%</span>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section info\">\n",
    "        <h2>üìç Informaci√≥n del Proyecto</h2>\n",
    "        <table>\n",
    "            <tr><td><strong>Nombre Completo:</strong></td><td>{proyecto.get('nombre', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Regi√≥n:</strong></td><td>{proyecto.get('region', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Provincia:</strong></td><td>{proyecto.get('provincia', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Comunas:</strong></td><td>{', '.join(proyecto.get('comunas', ['N/D']))}</td></tr>\n",
    "            <tr><td><strong>Tipo de Obra:</strong></td><td>{proyecto.get('tipo_obra', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Etapa:</strong></td><td>{proyecto.get('etapa', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>Mandante:</strong></td><td>{proyecto.get('mandante', 'N/D')}</td></tr>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Secci√≥n de presupuesto\n",
    "        if tiene_presupuesto:\n",
    "            validacion = presupuesto.get('validacion', {})\n",
    "            \n",
    "            html += f\"\"\"\n",
    "    <div class=\"section presupuesto\">\n",
    "        <h2>üí∞ Informaci√≥n Presupuestaria</h2>\n",
    "        <p class=\"total\">Total del Proyecto: ${presupuesto.get('total_con_iva', 0):,.0f} CLP</p>\n",
    "        \n",
    "        <table>\n",
    "            <tr><td><strong>Total Neto:</strong></td><td>${presupuesto.get('total_neto', 0):,.0f} CLP</td></tr>\n",
    "            <tr><td><strong>IVA (19%):</strong></td><td>${presupuesto.get('iva', 0):,.0f} CLP</td></tr>\n",
    "            <tr><td><strong>Total con IVA:</strong></td><td><strong>${presupuesto.get('total_con_iva', 0):,.0f} CLP</strong></td></tr>\n",
    "        </table>\n",
    "        \n",
    "        <h3>‚úÖ Validaci√≥n de C√°lculos</h3>\n",
    "        <table>\n",
    "            <tr><td><strong>IVA Correcto:</strong></td><td>{'‚úÖ S√≠' if validacion.get('iva_correcto') else '‚ùå No'}</td></tr>\n",
    "            <tr><td><strong>Total Correcto:</strong></td><td>{'‚úÖ S√≠' if validacion.get('total_correcto') else '‚ùå No'}</td></tr>\n",
    "            <tr><td><strong>F√≥rmula:</strong></td><td>{validacion.get('formula_aplicada', 'N/D')}</td></tr>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        else:\n",
    "            html += f\"\"\"\n",
    "    <div class=\"section warning\">\n",
    "        <h2>üí∞ Informaci√≥n Presupuestaria</h2>\n",
    "        <p><strong>Este documento no contiene datos presupuestarios detallados.</strong></p>\n",
    "        <p>Tipo de documento: {tipo_doc.replace('_', ' ').title()}</p>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Items presupuestarios si existen\n",
    "        if items:\n",
    "            html += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h2>üìù Items Presupuestarios ({len(items)} items)</h2>\n",
    "        <table>\n",
    "            <thead>\n",
    "                <tr><th>C√≥digo MOP</th><th>Descripci√≥n</th><th>Unidad</th><th>Cantidad</th><th>P.Unitario</th><th>Total</th></tr>\n",
    "            </thead>\n",
    "            <tbody>\"\"\"\n",
    "            \n",
    "            for item in items[:20]:  # Primeros 20 items\n",
    "                html += f\"\"\"\n",
    "                <tr>\n",
    "                    <td>{item.get('codigo_mop', 'N/D')}</td>\n",
    "                    <td>{item.get('descripcion', 'N/D')[:50]}...</td>\n",
    "                    <td>{item.get('unidad', 'N/D')}</td>\n",
    "                    <td>{item.get('cantidad', 0):,.2f}</td>\n",
    "                    <td>${item.get('precio_unitario', 0):,.0f}</td>\n",
    "                    <td>${item.get('total', 0):,.0f}</td>\n",
    "                </tr>\"\"\"\n",
    "            \n",
    "            if len(items) > 20:\n",
    "                html += f\"\"\"\n",
    "                <tr style=\"background: #fff3cd;\">\n",
    "                    <td colspan=\"6\" style=\"text-align: center;\">‚ö†Ô∏è Mostrando 20 de {len(items)} items totales</td>\n",
    "                </tr>\"\"\"\n",
    "            \n",
    "            html += \"\"\"\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\"\"\"\n",
    "        \n",
    "        # Informaci√≥n del an√°lisis\n",
    "        html += f\"\"\"\n",
    "    <div class=\"section\">\n",
    "        <h3>‚ÑπÔ∏è Informaci√≥n del An√°lisis</h3>\n",
    "        <table>\n",
    "            <tr><td><strong>Fecha:</strong></td><td>{datetime.now().strftime('%d/%m/%Y %H:%M')}</td></tr>\n",
    "            <tr><td><strong>Modelo:</strong></td><td>{metadata.get('modelo_usado', 'N/D')}</td></tr>\n",
    "            <tr><td><strong>C√≥digos MOP Detectados:</strong></td><td>{metadata.get('codigos_mop_detectados', 0)}</td></tr>\n",
    "            <tr><td><strong>M√©todo:</strong></td><td>{'An√°lisis Fallback' if metadata.get('es_fallback') else 'An√°lisis Claude'}</td></tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        \n",
    "        return html\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES PRINCIPALES\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_single_document(filename: str):\n",
    "    \"\"\"\n",
    "    Analiza un √∫nico documento de texto ya extra√≠do.\n",
    "    \"\"\"\n",
    "    text_file = RESULTS_DIR / filename\n",
    "    \n",
    "    if not text_file.exists():\n",
    "        print(f\"‚ùå Archivo no encontrado: {filename}\")\n",
    "        print(f\"   Buscando en: {text_file}\")\n",
    "        \n",
    "        # Buscar archivos similares\n",
    "        similar_files = list(RESULTS_DIR.glob(f\"*{filename.split('_')[0]}*_texto.txt\"))\n",
    "        if similar_files:\n",
    "            print(f\"   üìÅ Archivos similares encontrados:\")\n",
    "            for f in similar_files:\n",
    "                print(f\"      - {f.name}\")\n",
    "        return None\n",
    "    \n",
    "    analyzer = MOPBudgetAnalyzer(client)\n",
    "    result = analyzer.analyze_document_with_claude(text_file)\n",
    "    \n",
    "    if result['success']:\n",
    "        # Generar reporte HTML\n",
    "        html_report = analyzer.generate_html_report(result['analysis'], result.get('quick_analysis'))\n",
    "        display(HTML(html_report))\n",
    "        \n",
    "        # Guardar HTML\n",
    "        html_file = RESULTS_DIR / f\"{text_file.stem}_reporte.html\"\n",
    "        with open(html_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_report)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Reporte HTML guardado: {html_file}\")\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"‚ùå Error en el an√°lisis: {result.get('error', 'Unknown error')}\")\n",
    "        return result\n",
    "\n",
    "def analyze_all_documents_auto():\n",
    "    \"\"\"Versi√≥n autom√°tica sin confirmaci√≥n.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ AN√ÅLISIS AUTOM√ÅTICO DE TODOS LOS DOCUMENTOS MOP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    text_files = list(RESULTS_DIR.glob(\"*_texto.txt\"))\n",
    "    \n",
    "    if not text_files:\n",
    "        print(\"‚ùå No hay archivos de texto para analizar\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nüìö Procesando {len(text_files)} archivos autom√°ticamente...\")\n",
    "    \n",
    "    analyzer = MOPBudgetAnalyzer(client)\n",
    "    results = []\n",
    "    total_cost = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for i, text_file in enumerate(text_files, 1):\n",
    "        print(f\"\\n[{i}/{len(text_files)}] Procesando: {text_file.name}\")\n",
    "        result = analyzer.analyze_document_with_claude(text_file)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            total_cost += result['cost']\n",
    "            total_time += result['time']\n",
    "        \n",
    "        # Delay entre an√°lisis (excepto el √∫ltimo)\n",
    "        if i < len(text_files):\n",
    "            print(f\"   ‚è≥ Esperando 30s antes del siguiente...\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completado: {len([r for r in results if r['success']])}/{len(text_files)} exitosos\")\n",
    "    return results\n",
    "\n",
    "def test_budget_correction():\n",
    "    \"\"\"\n",
    "    Prueba las correcciones de presupuesto con datos conocidos.\n",
    "    \"\"\"\n",
    "    print(\"üßÆ TEST DE CORRECCI√ìN DE PRESUPUESTO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Datos del documento real\n",
    "    datos_documento = {\n",
    "        'total_neto': 604200524,\n",
    "        'iva_declarado': 114798100,\n",
    "        'total_declarado': 718998624\n",
    "    }\n",
    "    \n",
    "    # Verificaciones\n",
    "    iva_calculado = datos_documento['total_neto'] * 0.19\n",
    "    total_calculado = datos_documento['total_neto'] + datos_documento['iva_declarado']\n",
    "    \n",
    "    print(f\"üìä DATOS DEL DOCUMENTO:\")\n",
    "    print(f\"   Total Neto: ${datos_documento['total_neto']:,.0f}\")\n",
    "    print(f\"   IVA declarado: ${datos_documento['iva_declarado']:,.0f}\")\n",
    "    print(f\"   Total declarado: ${datos_documento['total_declarado']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüîç VERIFICACIONES:\")\n",
    "    print(f\"   IVA calculado (19%): ${iva_calculado:,.0f}\")\n",
    "    print(f\"   Total calculado: ${total_calculado:,.0f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ VALIDACIONES:\")\n",
    "    iva_correcto = abs(iva_calculado - datos_documento['iva_declarado']) < 100\n",
    "    total_correcto = total_calculado == datos_documento['total_declarado']\n",
    "    \n",
    "    print(f\"   IVA correcto: {'‚úÖ S√ç' if iva_correcto else '‚ùå NO'}\")\n",
    "    print(f\"   Total correcto: {'‚úÖ S√ç' if total_correcto else '‚ùå NO'}\")\n",
    "    \n",
    "    if iva_correcto and total_correcto:\n",
    "        print(f\"\\nüéØ RESULTADO: Los c√°lculos son correctos\")\n",
    "        print(f\"   F√≥rmula: ${datos_documento['total_neto']:,.0f} + ${datos_documento['iva_declarado']:,.0f} = ${datos_documento['total_declarado']:,.0f}\")\n",
    "    \n",
    "    return {\n",
    "        'datos_originales': datos_documento,\n",
    "        'iva_calculado': int(iva_calculado),\n",
    "        'total_calculado': int(total_calculado),\n",
    "        'validaciones': {\n",
    "            'iva_correcto': iva_correcto,\n",
    "            'total_correcto': total_correcto\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALIZADOR MOP COMPLETO CARGADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFunciones disponibles:\")\n",
    "print(\"  ‚Ä¢ analyze_single_document('bases1_texto.txt') - Analiza un documento espec√≠fico\")\n",
    "print(\"  ‚Ä¢ analyze_all_documents() - Analiza todos los documentos extra√≠dos\")\n",
    "print(\"  ‚Ä¢ test_budget_correction() - Prueba correcci√≥n de presupuesto\")\n",
    "print(\"\\nüí° Flujo recomendado:\")\n",
    "print(\"  1. test_budget_correction() - Verificar correcciones\")\n",
    "print(\"  2. analyze_single_document('nombre_archivo_texto.txt') - Probar con uno\")\n",
    "print(\"  3. analyze_all_documents() - Procesar todos\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130dd24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fix aplicado correctamente\n",
      "üí° Ahora ejecuta:\n",
      "   >>> result = analyze_single_document('bases1_texto.txt')\n",
      "\n",
      "La funci√≥n regex problem√°tica ha sido reemplazada con una versi√≥n simplificada que no causar√° IndexError.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4-FIX: CORRECCI√ìN CORRECTA DEL ERROR DE REGEX\n",
    "# ============================================================================\n",
    "\n",
    "# Reemplazar directamente la funci√≥n problem√°tica en la clase\n",
    "def _extract_project_info_regex_fixed(self, text: str) -> Dict:\n",
    "    \"\"\"Extrae informaci√≥n del proyecto usando regex (VERSI√ìN CORREGIDA).\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    info = {\n",
    "        \"nombre\": \"\",\n",
    "        \"region\": \"\",\n",
    "        \"comunas\": [],\n",
    "        \"tipo_obra\": \"\",\n",
    "        \"etapa\": \"\",\n",
    "        \"provincia\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Buscar nombre del proyecto\n",
    "    if \"conservaci√≥n\" in text_lower and \"caminos\" in text_lower:\n",
    "        if \"comunidades ind√≠genas\" in text_lower:\n",
    "            if \"etapa xii\" in text_lower or \"etapa 12\" in text_lower:\n",
    "                info[\"nombre\"] = \"Conservaci√≥n de caminos de acceso a comunidades ind√≠genas Etapa XII\"\n",
    "            else:\n",
    "                info[\"nombre\"] = \"Conservaci√≥n de caminos de acceso a comunidades ind√≠genas\"\n",
    "        else:\n",
    "            info[\"nombre\"] = \"Conservaci√≥n de caminos\"\n",
    "    \n",
    "    if not info[\"nombre\"]:\n",
    "        info[\"nombre\"] = \"Proyecto MOP\"\n",
    "    \n",
    "    # Buscar etapa\n",
    "    if \"etapa xii\" in text_lower or \"etapa 12\" in text_lower:\n",
    "        info[\"etapa\"] = \"Etapa XII\"\n",
    "    \n",
    "    # Buscar regi√≥n - SIMPLIFICADO\n",
    "    if \"los r√≠os\" in text_lower or \"regi√≥n de los r√≠os\" in text_lower:\n",
    "        info[\"region\"] = \"Los R√≠os\"\n",
    "    else:\n",
    "        region_match = re.search(r'regi√≥n[:\\s]+([^,\\n.]+)', text_lower)\n",
    "        if region_match:\n",
    "            info[\"region\"] = region_match.group(1).strip().title()\n",
    "    \n",
    "    # Buscar provincia - SIMPLIFICADO\n",
    "    if \"del ranco\" in text_lower or \"provincia del ranco\" in text_lower:\n",
    "        info[\"provincia\"] = \"Del Ranco\"\n",
    "    else:\n",
    "        provincia_match = re.search(r'provincia[:\\s]+([^,\\n.]+)', text_lower)\n",
    "        if provincia_match:\n",
    "            info[\"provincia\"] = provincia_match.group(1).strip().title()\n",
    "    \n",
    "    # Buscar comunas - SIMPLIFICADO\n",
    "    comunas_encontradas = []\n",
    "    if \"lago ranco\" in text_lower:\n",
    "        comunas_encontradas.append(\"Lago Ranco\")\n",
    "    if \"futrono\" in text_lower:\n",
    "        comunas_encontradas.append(\"Futrono\")\n",
    "    if \"valdivia\" in text_lower:\n",
    "        comunas_encontradas.append(\"Valdivia\")\n",
    "    \n",
    "    info[\"comunas\"] = comunas_encontradas if comunas_encontradas else [\"Por determinar\"]\n",
    "    \n",
    "    # Tipo de obra\n",
    "    if \"conservaci√≥n\" in text_lower:\n",
    "        info[\"tipo_obra\"] = \"Conservaci√≥n\"\n",
    "    elif \"construcci√≥n\" in text_lower:\n",
    "        info[\"tipo_obra\"] = \"Construcci√≥n\"\n",
    "    elif \"mejoramiento\" in text_lower:\n",
    "        info[\"tipo_obra\"] = \"Mejoramiento\"\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Aplicar el fix correctamente\n",
    "MOPBudgetAnalyzer._extract_project_info_regex = _extract_project_info_regex_fixed\n",
    "\n",
    "print(\"‚úÖ Fix aplicado correctamente\")\n",
    "print(\"üí° Ahora ejecuta:\")\n",
    "print(\"   >>> result = analyze_single_document('bases1_texto.txt')\")\n",
    "print(\"\\nLa funci√≥n regex problem√°tica ha sido reemplazada con una versi√≥n simplificada que no causar√° IndexError.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f6935b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ AN√ÅLISIS AUTOM√ÅTICO DE TODOS LOS DOCUMENTOS MOP\n",
      "================================================================================\n",
      "\n",
      "üìö Procesando 3 archivos autom√°ticamente...\n",
      "\n",
      "[1/3] Procesando: bases2_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases2_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 0\n",
      "üìä Caracteres: 338,247 ‚Üí 82,521\n",
      "üéØ Tokens estimados: 20,630\n",
      "‚è≥ Procesando con Claude...\n",
      "‚ùå Error: No se pudo extraer JSON de la respuesta\n",
      "   ‚è≥ Esperando 30s antes del siguiente...\n",
      "\n",
      "[2/3] Procesando: bases3_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases3_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 155\n",
      "üìä Caracteres: 308,486 ‚Üí 70,574\n",
      "üéØ Tokens estimados: 17,644\n",
      "‚è≥ Procesando con Claude...\n",
      "‚úÖ An√°lisis completado\n",
      "   ‚è±Ô∏è Tiempo: 7.2s\n",
      "   üí∞ Costo: $0.0047\n",
      "   üìä Items extra√≠dos: 0\n",
      "   üíæ Guardado: bases3_texto_analisis_completo.json\n",
      "   ‚è≥ Esperando 30s antes del siguiente...\n",
      "\n",
      "[3/3] Procesando: bases1_texto.txt\n",
      "\n",
      "ü§ñ Analizando con Claude: bases1_texto.txt\n",
      "============================================================\n",
      "üìÑ Tipo detectado: presupuesto\n",
      "üéØ C√≥digos MOP: 27\n",
      "üìä Caracteres: 221,552 ‚Üí 67,299\n",
      "üéØ Tokens estimados: 16,825\n",
      "‚è≥ Procesando con Claude...\n",
      "‚úÖ An√°lisis completado\n",
      "   ‚è±Ô∏è Tiempo: 10.4s\n",
      "   üí∞ Costo: $0.0046\n",
      "   üìä Items extra√≠dos: 3\n",
      "   üíæ Guardado: bases1_texto_analisis_completo.json\n",
      "\n",
      "‚úÖ Completado: 2/3 exitosos\n"
     ]
    }
   ],
   "source": [
    "results = analyze_all_documents_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbb57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
